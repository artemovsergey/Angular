# Windows, Linux, and Azure Deployment

Наше ценное путешествие по ASP.NET Core и разработке на Angular подходит к концу. Два
проекты, над которыми мы работали с главы 1 "Знакомство с ASP.NET и Angular" - HealthCheck и
WorldCities - теперь являются потенциально отгружаемыми продуктами и в основном готовы к публикации в подходящей среде для оценки.
В этой главе мы рассмотрим следующие темы:
- Подготовка нашего приложения к производству, где мы узнаем несколько полезных стратегий оптимизации для
переноса нашего приложения в производственную папку
- развертывание Windows, где мы увидим, как развернуть веб-приложение HealthCheck
на виртуальную машину Windows Server и опубликовать его в Интернете с помощью Internet Information Services (IIS) с помощью нового приложения.
Services (IIS) с помощью новой модели хостинга в процессе
- развертывание Linux, где мы развернем веб-приложение WorldCities на виртуальной машине Linux CentOS
и опубликуем его в Интернете с помощью веб-сервера Kestrel через прокси-сервер на базе Nginx
прокси
- развертывание службы приложений Azure, где мы развернем наше веб-приложение HealthCheck на полностью управляемом экземпляре MS
Azure web app fully managed instance без необходимости создания инфраструктуры на базе ВМ.
Конечная цель этой длинной и амбициозной главы - изучить необходимые инструменты и методы для
развертывания приложения ASP.NET Core и Angular на рабочем хостинг-сервере Windows и/или Linux, а также в облачной среде.
а также в облачной среде: давайте приступим к этой последней попытке!

# Технические требования
В этой главе нам понадобятся все предыдущие технические требования, перечисленные в главах 1-14,
а также следующие дополнительные пакеты.

Для развертывания в Windows:
- IIS (Windows Server)
- среда выполнения ASP.NET Core 6.0 (и установщик Windows Hosting Bundle для Win64 (Microsoft
.NET официальный сайт))
Для развертывания в Linux:
- ASP.NET Core 6.0 runtime для Linux (менеджер пакетов YUM)
- .NET 6 CLR для Linux (менеджер пакетов YUM)
- HTTP-сервер Nginx (менеджер пакетов YUM)
Как всегда, рекомендуется не устанавливать их сразу: мы будем подключать их в течение
в ходе главы, чтобы лучше понять их назначение в нашем проекте.
Файлы кода для этой главы можно найти здесь: https://github.com/PacktPublishing/ASP.NETCore-6-and-Angular/tree/main/Chapter_15.

# Готовимся к производству
В этом разделе мы рассмотрим, как можно доработать исходный код наших приложений, чтобы подготовить их к
использования в производстве. В основном мы будем заниматься кэшированием на стороне сервера и клиента, настройкой окружения и так далее. Во время работы мы воспользуемся возможностью узнать несколько полезных советов по оптимизации производства
советы, предлагаемые нашими фронтенд- и бэкенд-фреймворками.
Если говорить более конкретно, то мы рассмотрим следующее:
- Настройка конечных точек, где мы увидим, как мы будем настраивать рабочие конечные точки (имена хостов, псевдонимы и IP-адреса) и SSL-сертификаты на протяжении всей главы.
- Советы по развертыванию ASP.NET Core, где мы узнаем, как наш бэкэнд был оптимизирован для
производственного использования
- Советы по развертыванию Angular, где мы рассмотрим некоторые стратегии, используемые в шаблоне Visual Studio
для оптимизации этапа создания внешнего продукта.
Приступаем к работе!

# Настройка конечных точек
Когда веб-приложение публикуется в производственной среде, ему необходима публичная конечная точка (URL).
чтобы пользователи могли получить к нему доступ. Такой конечной точкой обычно является выделенное доменное имя (www.
myapp.com), доменное имя третьего уровня (myapp.someapps.com), путь в общем доменном имени
(www.someapps.com/myapp/) или IP-адрес (20.103.255.220).

Иногда эти конечные точки также настроены на использование нестандартных TCP-портов (www.myapp.
com:8080), подобно портам 40433 и 40080, которые мы использовали для локального размещения наших проектов
на этапе разработки: однако такой подход редко используется в производстве, поскольку он
это может привести к проблемам совместимости, ухудшению репутации сайта, SEO-недостаткам и так далее.

В нашем конкретном сценарии нам понадобится несколько конечных точек, поскольку мы собираемся опубликовать не менее
не менее четырех приложений - HealthCheck, HealthCheckAPI, WorldCities и WorldCitiesAPI - в разных местах.
Чтобы решить эту задачу без необходимости использовать нестандартные TCP-порты, полагаться на подпути или
покупать несколько доменов, мы предлагаем выбрать один из двух следующих путей:
- Использовать доменные имена третьего уровня из одного домена, находящегося в нашем распоряжении, и сопоставить их с
публичный IP-адрес производственного сервера с помощью публичных настроек DNS для этого домена.
- Использовать "поддельные" доменные имена и сопоставить их с публичным IP-адресом производственного сервера с помощью
файл HOSTS локальной машины
На протяжении всей этой главы мы будем использовать первый способ, создавая следующие доменные имена третьего уровня
имена:
- healthcheck-2022.ryadel.com - для приложения HealthCheck Angular
- healthcheck-api-2022.ryadel.com - для веб-интерфейса HealthCheckAPI
- worldcities-2022.ryadel.com - для приложения WorldCities Angular
- worldcities-api-2022.ryadel.com - для веб-интерфейса WorldCitiesAPI
Этот удобный выбор позволяет нам использовать один домен и один сертификат wildcard SSL (*.ryadel.
com) для всех наших нужд, что значительно экономит средства.
Те, у кого нет (или нет желания приобретать) домен и сертификат wildcard SSL, могут пойти альтернативным путем, создав несколько связок между публичными IP-адресами, назначенными серверам, которые мы собираемся
и некоторыми "фальшивыми" именами хостов, используя вышеупомянутые имена или даже более элегантные
альтернативы, такие как healthcheck.io, healthcheck-api.io и т. п.: мы вольны выбрать любое имя
поскольку они будут существовать только в нашем локальном окружении. В следующем разделе мы кратко объясним
как создать эти сопоставления с помощью файла HOSTS операционной системы.

# Настройка файла HOSTS
Самый простой и эффективный способ сопоставить имя хоста с заданным IP-адресом в любой операционной системе Windows, Linux,
и macOS является редактирование файла HOSTS, который используется ОС для окончательного сопоставления
хост-имен к IP-адресам до (и вместо) их разрешения через поиск DNS.

В системах Windows файл HOSTS находится по следующему адресу:

```
C:\Windows\System32\drivers\etc\hosts
```

В системах Linux и macOS файл HOSTS находится по следующему адресу:

```
/etc/hosts
```
Такой файл можно отредактировать с помощью текстового редактора следующим образом:

```
<IP.ADDRESS.0.1> healthcheck.io
<IP.ADDRESS.0.2> healthcheck-api.io
<IP.ADDRESS.0.3> worldcities.io
<IP.ADDRESS.0.4> worldcities-api.io
```
Нам не нужно делать это сейчас, поскольку мы еще не знаем этих IP-адресов: мы будем добавлять вышеуказанные записи
записи по всей этой главе, заменяя различные записи <IP.ADDRESS.0.N> на публичный IP-адрес
общедоступным IP-адресом виртуальной машины или службы приложений, которые мы собираемся использовать.

Чтобы отредактировать файл Windows HOSTS, нам понадобятся права администратора; в противном случае мы не сможем постоянно изменять его на диске.

На самом деле, создание таких "переопределений" в файле HOSTS локальной машины - это простой и
эффективный способ протестировать наши производственные веб-приложения, используя "настоящее" имя хоста (вместо простого IP-адреса)
без необходимости приобретать домен или SSL-сертификат. Однако такой выбор имеет
некоторые очевидные минусы, в том числе:
- Недоступность. Никто другой не сможет связаться с этими приложениями, если только они не подправят файл HOSTS
файл, как это делаем мы.
- Проблемы с TLS/SSL. Скорее всего, у нас не будет действительного сертификата TLS/SSL для этих "поддельных" доменов, а значит, нам придется жить с предупреждающими страницами браузера, исключениями безопасности, предупреждениями антивируса,
сбоями регистрации работников служб и так далее - даже если мы используем сертификат арендатора MS Azure
или самоподписанный сертификат TLS/SSL (подробнее об этом позже).
Если вы хотите пойти по пути файла HOSTS, убедитесь, что понимаете все эти недостатки.

# Другие приемлемые альтернативы
Те, кто не хочет следовать предложенным нами маршрутам, могут использовать любую подходящую альтернативу: собственные
доменные имена, дополнительные IP-адреса, DNS-записи, предоставленные третьими лицами, и так далее - при условии, что
если вы знаете, как правильно с ними обращаться.
То же самое касается сертификатов TLS/SSL, которые можно получить бесплатно с помощью некоторых специализированных
сервисов (например, ZeroSSL) или некоммерческих центров сертификации (например, Let's Encrypt), а не покупать их.
вместо того, чтобы покупать их.

Более того, если мы планируем разместить наше приложение с помощью Azure App Service (см. раздел "Развертывание Azure App Service
раздел ниже), мы можем использовать функцию App Service Managed Certificate для создания бесплатного сертификата TLS/SSL, управляемого Azure, что на самом деле очень просто.

Тем не менее, для простоты в этой главе мы будем использовать (и считать само собой разумеющимся) несколько
домены третьего уровня с сертификатом wildcard SSL. Те, кто хочет использовать одну из вышеупомянутых альтернатив, могут заменить эту технику на предпочитаемый ими подход: просто не забудьте изменить appsettings.json проектов ASP.
NET Core в файлах appsettings.json и/или /environments/environment.
prod.ts соответствующим образом.

# Советы по развертыванию ASP.NET Core
Как вы, скорее всего, уже знаете, ASP.NET Core позволяет разработчикам настраивать поведение приложения
в различных средах: наиболее распространенные из них - среда разработки, среда постановки и производственная среда.
среды. Текущая активная среда определяется во время выполнения с помощью проверки переменной окружения
переменной, которая может быть настроена и изменена из конфигурационных файлов проекта.
Эта переменная называется ASPNETCORE_ENVIRONMENT и, пока мы запускаем наш проект в Visual Studio,
ее можно установить с помощью файла /Properties/launchSettings.json, который управляет различными настройками, которые
которые будут применены к нашей локальной машине разработки при запуске веб-приложения.

# Файл launchSettings.json
Если мы посмотрим на файл launchSettings.json, то увидим, что он содержит некоторые специфические настройки
для каждого профиля выполнения нашего проекта. Для наглядного примера приведем содержимое файла
/Properties/launchSettings.json проекта HealthCheckAPI:

```json
{
 "$schema": "https://json.schemastore.org/launchsettings.json",
 "iisSettings": {
 "windowsAuthentication": false,
 "anonymousAuthentication": true,
 "iisExpress": {
 "applicationUrl": "http://localhost:40080",
 "sslPort": 40443
 }
 },
 "profiles": {
 "HealthCheckAPI": {
 "commandName": "Project",
 "dotnetRunMessages": true,
 "launchBrowser": false,
 "launchUrl": "swagger",
 "applicationUrl": "https://localhost:40443;http://localhost:40080",
 "environmentVariables": {
 "ASPNETCORE_ENVIRONMENT": "Development"
 }
 },
 "IIS Express": {
 "commandName": "IISExpress",
 "launchBrowser": false,
 "launchUrl": "swagger",
 "environmentVariables": {
 "ASPNETCORE_ENVIRONMENT": "Development"
 }
 }
 }
}
```
Как мы видим, в настоящее время установлено два профиля выполнения:
- Профиль IIS Express, который связан с HTTP-сервером IIS Express. Этот профиль будет
использоваться всякий раз, когда мы запускаем наш проект в режиме отладки, что можно сделать, нажав F5 (если только мы не изменили поведение отладки по умолчанию).
если мы не изменили поведение отладки по умолчанию).
- Профиль HealthCheckAPI, относящийся к самому приложению. Этот профиль будет
использоваться всякий раз, когда мы будем запускать наш проект с помощью .NET Core CLI (другими словами, командой dotnet
run console command).
Для обоих профилей переменная ASPNETCORE_ENVIRONMENT в настоящее время имеет значение Development,
это означает, что мы всегда будем запускать наши приложения в режиме разработки из Visual Studio, если только не изменим эти значения.
если мы не изменим эти значения.
Как различные окружения влияют на поведение нашего веб-приложения? В следующем разделе мы прольем
немного света на этот вопрос.

# Среды выполнения
Давайте начнем с краткого объяснения того, что происходит во время выполнения.
Сразу после запуска нашего веб-приложения ASP.NET Core считывает переменную окружения ASPNETCORE_ENVIRONMENT
и сохраняет ее значение в свойстве EnvironmentName экземпляра IWebHostEnvironment нашего приложения
который, как следует из его названия, предоставляет информацию о среде хостинга, в которой работает наше приложение.
в которой работает наше приложение. После установки эта переменная может быть использована программно - либо напрямую, либо
с некоторыми вспомогательными методами, чтобы определить поведение нашего приложения в любой момент жизненного цикла бэкенда.
Мы уже видели эти методы в действии в классе Program наших приложений ASP.NET Core.
например, вот что мы можем найти в исходном коде Program.cs HealthCheckAPI:

```Csharp
if (app.Environment.IsDevelopment())
{
 app.UseSwagger();
 app.UseSwaggerUI();
}
```
В предыдущих строках мы указываем нашему приложению регистрировать промежуточное ПО Swagger и SwaggerUI только в том случае.
если приложение запущено в среде разработки. Это условие, которое является частью большинства шаблонов веб-приложений Visual
Studio шаблонов веб-приложений, существует не просто так: это мера предосторожности, чтобы мы не
от случайного раскрытия нашей документации по OpenAPI в открытом доступе - если только мы явно не выберем
сделать это, переписав блок if.
Учитывая наш текущий сценарий, поскольку единственной целью нашего проекта HealthCheckAPI является взаимодействие с нашим
HealthCheck Angular, нет причин выпускать наш файл Swagger JSON или пользовательский интерфейс, который сделает
его более человекочитаемым: по этой самой причине мы можем оставить все как есть. Та же логика может
можно применить и к проекту WorldCitiesAPI.

Все было бы иначе, если бы мы имели дело с веб-интерфейсом, предназначенным для использования
из сторонних сервисов или произвольных клиентов: в этих обстоятельствах предоставление подробной
подробную документацию по API было бы разумным решением при условии, что
при условии соблюдения необходимых мер безопасности.

Пока мы находимся здесь, мы можем воспользоваться возможностью улучшить конфигурацию файла Program.cs
конфигурации файла Program.cs для рабочей и промежуточной сред, используя промежуточное программное обеспечение ExceptionHandler
вместо стандартного DeveloperExceptionPage. Однако прежде чем это сделать, было бы разумно сделать
шаг назад и вкратце ознакомиться с концепцией обработки ошибок в ASP.NET Core, чтобы лучше понять
основной контекст.

# Методы обработки ошибок
Согласно настройкам по умолчанию, все веб-приложения ASP.NET Core показывают подробные трассировки стека для ошибок сервера
используя промежуточное ПО DeveloperExceptionPageMiddleware. Это промежуточное ПО вставляется на ранней стадии конвейера промежуточного ПО
и может перехватывать любые необработанные исключения, выброшенные любым последующим промежуточным ПО, что очень полезно на этапе разработки.
очень полезно на этапе разработки; однако информация об исключениях и трассировка стека не должны
Однако информация об исключениях и трассировки стека не должны показываться, когда проект становится общедоступным.
По этой причине распространенной практикой безопасности является замена его на UseExceptionHandlerMiddleware
когда проект запускается в среде, не связанной с разработкой. Такое промежуточное ПО по-прежнему будет способно перехватывать
(и потенциально регистрировать) исключения, но вместо того, чтобы печатать всю необходимую информацию на специальной странице ошибок
он может быть настроен на перенаправление запроса на настраиваемый маршрут "ошибки", который может быть обработан
с помощью метода действия контроллера, метода Minimal API или чего-либо еще.
Теперь, когда мы все это знаем, мы можем настроить UseExceptionHandlerMiddleware, немного изменив
эту "условную" часть файла Program.cs следующим образом (новые строки выделены):

```Csharp
// Configure the HTTP request pipeline.
if (app.Environment.IsDevelopment())
{
 app.UseSwagger();
 app.UseSwaggerUI();
}
else
{
 app.UseExceptionHandler("/Error");
 app.MapGet("/Error", () => Results.Problem());
}
```
Как видно из приведенного выше кода, мы настроили промежуточное ПО обработчика исключений на
перенаправлять ошибки на маршрут /Error, а также добавили простой метод MinimalAPI для их обработки.

The Results.Problem() we’re returning produces a ProblemDetails response, a
JSON-formatted, machine-readable response message for specifying errors in HTTP APIs
based on https://tools.ietf.org/html/rfc7807.

После внесения этих изменений при каждом сбое нашего приложения ASP.NET Core на странице ошибок будут условно отображаться следующие сообщения:
- Среда разработки: Низкоуровневое/подробное сообщение об ошибке, такое как информация об исключении
и трассировка стека (только для разработчиков).
- Среда постановки или производственная среда: Высокоуровневое/общее сообщение о недоступности (для всех конечных пользователей).
Страница исключения разработчика содержит подробную серию полезных сведений об исключении и
запросе, например исключения и внутренние исключения, трассировки стека, параметры строки запроса, cookies,
и HTTP-заголовки.

Пока мы здесь, мы можем добавить еще одно промежуточное ПО, чтобы еще больше повысить уровень безопасности наших
HSTSMiddleware, которое добавляет значение заголовка HTTP Strict Transport Security (HSTS max age) во все наши ответы.
(HSTS) значение заголовка max age во все наши ответы.
Вот как мы можем это сделать (новый код выделен):

```Csharp
// Configure the HTTP request pipeline.
if (app.Environment.IsDevelopment())
{
 app.UseSwagger();
 app.UseSwaggerUI();
}
else
{
 app.UseExceptionHandler("/Error");
 app.MapGet("/Error", () => Results.Problem());
 app.UseHsts();
}
```
Заголовок HSTS соответствует некоторым хорошим практикам безопасности HTTP и поэтому очень желателен
для любого приложения, которое публично представлено в Интернете; однако он практически бесполезен (и может быть помехой)
во время отладки, поэтому мы устанавливаем его только для сред, не связанных с разработкой,
как и для пользовательской страницы ошибок.
Прежде чем двигаться дальше, давайте скопируем все обновления, которые мы внесли в файл Program.cs интерфейса HealthCheckAPI, в файл
WorldCitiesAPI в файл Program.cs, чтобы оба наших приложения могли воспользоваться этими удобными настройками.

# Правило(а) большого пальца
Теперь, когда мы увидели, как программно определить среду выполнения нашего веб-приложения и
заставить наш HTTP-конвейер действовать соответствующим образом, мы должны узнать, как правильно принять и адаптировать эти
условные практики, чтобы наилучшим образом соответствовать этим средам.
Поскольку среда разработки доступна только разработчикам, она всегда должна отдавать предпочтение отладочным
возможности отладки, а не производительность. Поэтому она должна избегать кэширования, использовать стратегии загрузки в память
чтобы быстро реагировать на изменения, и выдавать как можно больше диагностической информации (журналы, исключения,
и т. д.), чтобы помочь разработчикам оперативно понять, что происходит.

Если вы помните, что говорилось в главе 10, ASP.NET Core и Angular Unit Testing,
о разработке, управляемой тестами (TDD), вы должны легко понять, что среда разработки - это то место, где практика TDD проявляется наиболее ярко.

И наоборот, если речь идет о производственной среде, то для принятия таких решений лучше всего
применять следующие эмпирические правила:
- Включите кэширование, когда это возможно, чтобы сэкономить ресурсы и повысить производительность
- Убедитесь, что все ресурсы на стороне клиента (JavaScript, CSS-файлы и т. д.) упакованы, минифицированы,
и, возможно, обслуживаются из сети доставки контента (CDN).
- Отключите диагностические страницы ошибок и/или замените их дружественными, человекопонятными страницами ошибок
вместо них
- Включите протоколирование и мониторинг производства с помощью инструментов управления производительностью приложений
или других стратегий мониторинга, аудита и наблюдения в реальном времени.
- Внедряйте лучшие практики безопасности, предлагаемые фреймворками
- Внедряйте методологии Open Web Application Security Project (OWASP) для разработки программного обеспечения
разработки программного обеспечения, а также конфигурации сети, брандмауэра и сервера.
Это общие рекомендации (или хорошие практики), которые мы всегда должны серьезно учитывать при доработке внутренней части наших веб-приложений для использования в производстве.

А как насчет среды постановки? В основном она используется как предпроизводственная среда, в которой мы можем
выполнить (или заставить некоторых тестировщиков выполнить) наше внешнее тестирование, прежде чем дать добро на производственное
развертывание. В идеале ее физические характеристики должны повторять производственные, чтобы любые проблемы
которые могут возникнуть в производстве, сначала возникают в среде постановки, где их можно решить
без ущерба для пользователей.

Опять же, если мы вспомним наш анализ разработки, ориентированной на поведение, в главе 10,
ASP.NET Core и модульное тестирование Angular, мы можем с уверенностью сказать, что среда staging
среда будет идеальным местом для тестирования ожидаемого поведения любых новых
добавленных функций наших приложений, прежде чем выпускать их в производство.

Давайте продолжим наше знакомство со средами ASP.NET Core еще одним важным вопросом
вопроса: как установить правильное окружение при развертывании приложения (приложений)?

# Установка окружения в производстве
Что происходит с переменной ASPNETCORE_ENVIRONMENT, когда мы публикуем наше веб-приложение для
производственного развертывания, как мы это делали в главе 12, Прогрессивные веб-приложения, когда настраивали
профиль публикации на основе папок для наших проектов HealthCheckAPI и WorldCitiesAPI?
Как мы видим, заглянув в эти папки, файл launchSettings.json там не найти,
поскольку он не публикуется. Этого, конечно, следовало ожидать, поскольку он предназначен только для использования
Visual Studio и других локальных инструментов разработки.
Когда мы разместим приложение на рабочем сервере, нам придется вручную установить это значение, используя один из
следующих подходов:
- Специальная переменная окружения с тем же именем
- Специальные настройки платформы
- переключатель командной строки
Эти методы сильно зависят от операционной системы сервера. В следующих разделах мы рассмотрим
как выполнить их на серверах Windows и Linux.

Если никаких настроек, связанных с окружением, не найдено, веб-приложение всегда будет использовать производственное значение в качестве значения
по умолчанию, что является наиболее консервативным выбором с точки зрения производительности и безопасности, поскольку большинство отладочных
функций и диагностических сообщений будет отключено.
И наоборот, если окружение задается несколько раз (например, переменной окружения, а затем
переключатель командной строки), приложение будет использовать последнюю считанную настройку окружения, следуя таким образом каскадному правилу.

# Обновление файла(ов) appsettings.Production.json
Из главы 3, "Оглядеться вокруг", мы уже знаем, что параметры конфигурации, содержащиеся в файле
appsettings.json наших проектов ASP.NET Core, могут быть переопределены для конкретных сред выполнения с помощью специфических для среды файлов, таких как appsettings.Development.json и appsettings.
Production.json. Теперь, когда мы собираемся развернуть наши приложения в производстве, нам следует воспользоваться возможностью
просмотреть эти файлы и посмотреть, не нужно ли нам изменить некоторые из этих настроек.

# HealthCheckAPI
Давайте начнем с проекта HealthCheckAPI. Собственно говоря, в этом проекте не используются строки подключения
строк подключения, секретных ключей или чего-либо, что может потребовать переопределения в производственной среде - за исключением
ключа AllowedCORS, который мы добавили в главе 12 "Прогрессивные веб-приложения".
Если мы хотим, чтобы наш Web API был доступен только с имени хоста приложения HealthCheck Angular,
нам нужно будет создать новый файл appsettings.Production.json, чтобы переопределить этот ключ с помощью следующей команды
команда:

```json
{
 "AllowedCORS": "https://healthcheck-2022.ryadel.com"
}
```
Разумеется, вышеуказанное значение подойдет только для нашего конкретного сценария, поскольку мы используем доменные имена третьего уровня
доменные имена третьего уровня домена ryadel.com: тем, кто использует другие домены (или любой другой
подход) должны установить это значение в соответствии со своим конкретным выбором.

Приведенный выше файл appsettings.Production.json был добавлен в репозиторий GitHub
для этой главы только в справочных целях: однако размещение этого файла под тем же
широко считается плохой практикой, даже если он не содержит личной или конфиденциальной информации, поскольку он может быть случайно развернут в производстве и, следовательно,
и, следовательно, переопределить файл, уже имеющийся на сервере, который может быть подвержен независимым от кода
изменениям с течением времени. Чтобы минимизировать этот риск, лучше хранить его в отдельном месте
и вручную копировать его на сервер, когда это необходимо.

Если мы не хотим ограничивать политику CORS для нашего производственного приложения, мы можем не создавать файл
appsettings.Production.json для проекта HealthCheckAPI.
Теперь перейдем к проекту WorldCitiesAPI.

# WorldCitiesAPI
Ситуация для нашего WorldCitiesAPI немного сложнее, поскольку у нас есть несколько ключей, которые мы можем
которые мы могли бы переопределить в производстве: строка подключения для доступа к нашей базе данных SQL и весь блок
JwtSetting.

Вот как должен выглядеть подходящий файл appsettings.Production.json (соответствующие настройки выделены):

```json
{
 "ConnectionStrings": {
 "DefaultConnection": "PUT-YOUR-PRODUCTION-CONNECTION-STRING-HERE"
 },
 "JwtSettings": {
 "Audience": "https://worldcities-2022.ryadel.com"
 },
 "AllowedCORS": "https://worldcities-2022.ryadel.com"
}
```
Обязательно замените значение ConnectionStrings:DefaultConnection на реальную строку подключения
строкой; кроме того, установите значения JwtSettings:Audience и AllowedCORS в соответствии с конечной точкой приложения Angular, которую вы планируете использовать.
производственной конечной точки приложения Angular, которую вы планируете использовать.

Опять же, пример файла appsettings.Production.json для проекта WorldCitiesAPI с
с вышеуказанными значениями был добавлен в репозиторий GitHub для этой главы, только для справки
только в справочных целях; на самом деле мы должны создать и/или обновить его на рабочем
сервере (или службе) после развертывания нашего приложения.

Теперь мы готовы перейти к следующим шагам: развертыванию нашего приложения в производственной среде на Windows, Linux и Azure. Однако прежде чем это сделать, давайте обсудим доступные нам
доступные нам режимы развертывания.

# Режимы развертывания .NET
В главе 12 "Прогрессивные веб-приложения", когда мы создали наш первый профиль публикации для развертывания приложения в
локальную папку, мы не изменили настройки режима развертывания, оставив их прежними. По правде говоря,
мы сделали это потому, что это не имело бы никакого значения, поскольку мы использовали эту сборку только для того, чтобы украсть несколько
сгенерированные файлы, связанные с прогрессивным веб-приложением (PWA), и использовали их для регистрации нашего рабочего сервиса из
стандартного отладочного запуска Visual Studio.
Однако режим развертывания .NET - это очень важная функция конфигурации, которую нам определенно
чтобы сделать правильный выбор, когда нам придется развернуть наше приложение для
производственного использования.
Давайте сейчас попробуем пролить свет на три различных типа развертывания, доступных в Visual
Studio для приложений .NET:
- Framework-dependent deployment (FDD): Как следует из названия, такой режим развертывания
требует наличия .NET Framework, который должен быть установлен и доступен на целевой системе.
Другими словами, мы создадим переносимое приложение .NET до тех пор, пока сервер хостинга
поддерживает его.
- Самостоятельное развертывание (SCD): Этот режим развертывания не зависит от наличия компонентов .NET
компонентов на целевой системе. Все компоненты, включая библиотеки .NET и среду выполнения,
будут включены в производственную сборку. Если сервер хостинга поддерживает .NET, приложение будет работать
в изолированном режиме, отделяясь от других приложений .NET. Сборки SCD будут включать
исполняемый файл (файл .exe на платформах Windows), а также файл .dll, содержащий среду выполнения приложения.
- Framework-dependent executable (FDE): В этом режиме развертывания создается исполняемый файл, который запускается на хостинговом сервере, где должны быть установлены среды выполнения .NET и ASP.NET Core
на котором должны быть установлены среды выполнения .NET и ASP.NET Core. Таким образом, этот режим скорее похож на FDD, поскольку оба они
зависят от фреймворка.
Давайте теперь попробуем разобраться в плюсах и минусах каждого режима развертывания.

## Фреймворк-зависимое развертывание
Использование режима FDD дает разработчику ряд преимуществ, в том числе следующие:
- Независимость от платформы: Нет необходимости определять целевую операционную систему, так как среда выполнения .NET
установленная на хостинговом сервере, без проблем справится с выполнением приложения независимо от его платформы.
независимо от платформы.
- Небольшой размер пакета: Пакет развертывания будет небольшим, поскольку он будет содержать только
runtime и сторонние зависимости. Самого .NET там не будет, поскольку мы ожидаем, что он
уже присутствует на целевой машине.
- Последняя версия: Согласно настройкам по умолчанию, FDD всегда будет использовать последнюю обслуживаемую среду выполнения
установленную на целевой системе, со всеми последними исправлениями безопасности.
- Более высокая производительность в сценариях с несколькими хостингами: Если на хостинговом сервере установлено несколько приложений .NET
то общие ресурсы позволят нам сэкономить место в хранилище и, что самое главное,
уменьшить потребление памяти.
Однако у этого режима развертывания есть и ряд недостатков, в том числе следующие:
- Сниженная совместимость: Для нашего приложения потребуется среда выполнения .NET с версией, совместимой с
используемой нашим приложением (или более поздней). Если на хостинговом сервере установлена предыдущая версия, наше приложение
не сможет работать.
- Проблемы стабильности: Если бы среда выполнения .NET и/или библиотеки изменили свое поведение (другими словами
другими словами, если они внесут изменения или уменьшат совместимость по соображениям безопасности или лицензирования),
наше приложение также может быть затронуто этими изменениями.

## Самостоятельное развертывание
Использование режима SCD имеет два больших преимущества, которые могут легко перевесить недостатки в отношении
некоторых конкретных сценариев:
- Полный контроль над опубликованной версией .NET, независимо от того, что установлено на хостинговом сервере
сервере (или что произойдет с ним в будущем).
- Отсутствие проблем с совместимостью, поскольку все необходимые библиотеки поставляются в комплекте

К сожалению, есть и ряд существенных недостатков:
- Зависимость от платформы: Предоставление среды выполнения вместе с производственным пакетом требует от разработчика заранее выбрать целевые платформы сборки.
- Увеличенный размер пакета: Дополнительное присутствие ресурсов времени выполнения определенно
Дополнительное присутствие ресурсов времени выполнения определенно приведет к увеличению объема дискового пространства. Это может стать серьезным ударом, если мы планируем развернуть несколько приложений SCD .NET Core на одном хостинговом сервере, поскольку каждое из них потребует значительного
дискового пространства.
Проблема размера пакета автономного развертывания была решена в .NET Core 3.0 с появлением функции
функции обрезки приложений (также называемой компоновщиком сборок), которая, по сути, обрезает неиспользуемые сборки. Этот подход был усовершенствован в последующих версиях .NET, где сборки
"вскрываются" и очищаются от типов и членов, не используемых приложением, что еще больше уменьшает их размер.
размер.

## Фреймворк-зависимый исполняемый файл
Режим развертывания FDE был введен в .NET Core 2.2 и, начиная с версии 3.0, является режимом по умолчанию для базовой команды dotnet publish (если не указано никаких опций). Этот новый подход
имеет следующие преимущества:
- Небольшой размер пакета, последняя версия и лучшая производительность в сценариях с несколькими хостингами, как и
как и режим FDD
- Простота запуска: Развернутый исполняемый файл может быть запущен и выполнен напрямую, без необходимости
вызывать dotnet CLI
Этот подход также имеет некоторые недостатки:
- Сниженная совместимость: Как и FDD, приложение требует наличия среды исполнения ASP.NET Core с версией
совместимой с той, которая используется в нашем приложении (или более поздней).
- Проблемы со стабильностью: Опять же, если среда выполнения ASP.NET Core и/или библиотеки изменят свое
поведение, эти изменения могут привести к поломке приложения или изменению его поведения
- Зависимость от платформы: Поскольку приложение представляет собой исполняемый файл, его необходимо публиковать для каждой разной
целевой платформы

Как нетрудно догадаться, все эти три режима развертывания могут быть как хорошими, так и плохими, в зависимости от
ряда факторов, таких как степень контроля над сервером развертывания, количество приложений ASP.
NET Core, сколько приложений ASP Core мы планируем опубликовать, а также аппаратные и программные возможности целевой системы.
Как правило, если у нас есть права на установку и обновление системных пакетов на сервере развертывания, режимы FDD должны работать хорошо; и наоборот, если мы размещаем наши приложения на облачном хостинге
провайдера, который не имеет нужной нам среды исполнения .NET, SCD будет наиболее логичным выбором.

Доступное дисковое пространство и объем памяти также будут играть важную роль, особенно если мы планируем опубликовать
несколько приложений.

Тем не менее, мы будем использовать режим развертывания FDD (по умолчанию), поскольку наш текущий сценарий требует
публикации двух разных приложений, использующих одну и ту же версию среды исполнения ASP.NET Core, на одном и том же
сервере.

# Советы по развертыванию Angular
Теперь давайте обратимся к фронтенду, чтобы правильно понять, как шаблон Visual Studio, который мы использовали для создания двух приложений
который мы использовали для создания двух наших приложений, справляется с задачами развертывания Angular на производстве.
Само собой разумеется, что те же самые передовые методы, которые мы определили для бэкенда, сохраняют свою
сохраняют свою ценность и на фронтенде, как мы увидим в ближайшее время. Другими словами, производительность и безопасность
по-прежнему будут главными целями в этом отношении.
Теперь давайте попробуем понять, как Angular CLI решает задачи публикации и развертывания наших приложений
задачи.

# ng serve, ng build и файл package.json
Как мы уже знаем, каждый раз, когда мы запускаем один из наших Angular-проектов в Visual Studio, фактическое приложение обслуживается с помощью экземпляра сервера Angular CLI в памяти: этот сервер запускается в
Visual Studio с помощью команды ng serve, как мы можем видеть, взглянув на консольное окно, которое
которое автоматически открывается во время запуска для размещения этого процесса.
Если мы посмотрим на это окно, то сможем увидеть это наглядно, как показано на следующем скриншоте:

![image](https://github.com/artemovsergey/Angular/assets/26972859/8b6654e4-a6a5-4609-9d73-6d9f2d20e2ad)

И наоборот, когда мы хотим скомпилировать наше приложение для производства, как мы узнали в главе 12 "Прогрессивные веб-приложения", нам нужно использовать команду ng build CLI:
```
> ng build
```
Приведенная выше команда создает пакет Angular с несколькими функциями оптимизации, предназначенными для развертывания на производстве, включая следующие:
- Компиляция с опережением времени (AOT): Преобразует код HTML и TypeScript в эффективный
JavaScript, чтобы обеспечить более быстрый рендеринг в браузере. Режим по умолчанию (используется для
ng serve), называемый just-in-time (JIT) compilation, компилирует приложение в браузере во время выполнения
и поэтому является гораздо более медленной и менее оптимизированной альтернативой.
- Производственный режим: Это позволяет ускорить работу приложения за счет отключения некоторых специфических для разработки
проверки, такие как двойные циклы обнаружения изменений.
- Пакетирование: Это объединяет различные файлы приложения и сторонних разработчиков (пакеты npm) в несколько
пакетов.
- Минификация: Удаляет пробельные символы, комментарии, необязательные маркеры и любые ненужные
символов и артефактов в файлах HTML, JavaScript и CSS.
- Углификация: Это внутренняя переработка кода JavaScript для сокращения имен переменных и функций.
Это также сделает наш опубликованный код менее читаемым, что часто бывает полезно, поскольку
это защитит наше приложение от попыток обратного инжиниринга.
- Очистка мертвого кода: Удаляются все модули, на которые нет ссылок, и/или неиспользуемые файлы, фрагменты или секции кода.
Как мы видим, все вышеперечисленные функции направлены на повышение производительности и безопасности
нашей производственной сборки.

# Дифференциальная загрузка
Еще одна приятная функция, о которой стоит упомянуть, - дифференциальная загрузка, которая появилась в Angular 8 и
включается по умолчанию при использовании команды ng build.
Дифференциальная загрузка - это способ Angular преодолеть проблемы совместимости между различными браузерами,
особенно старых; другими словами, тех, которые все еще основаны на старых версиях JavaScript.
Как мы видим из файла tsconfig.json, размещенного в корне наших проектов Angular, наш код TypeScript будет транспилирован и собран в ES2017, также известный как ECMAScript 2017, синтаксис JavaScript, совместимый с большинством версий JavaScript.
синтаксис, совместимый с подавляющим большинством современных браузеров. Тем не менее, все еще существует ряд
пользователей со старыми клиентами, такими как старые настольные компьютеры, ноутбуки и/или мобильные устройства, которые привязаны к ES5
и более ранними версиями.
Чтобы обойти эту проблему, предыдущие версии Angular, как и большинство других фронтенд-фреймворков, предоставляли ряд вспомогательных библиотек (известных как полифиллы), которые условно реализовывали
недостающие функции для тех браузеров, которые не поддерживали их изначально. К сожалению, такое
обходной путь значительно увеличивал производственный пакет, что приводило к снижению производительности для
всех пользователей, включая тех, кто использует современные браузеры, которым эти полифиллы изначально не нужны.

Дифференциальная загрузка решает эту проблему, генерируя два отдельных набора пакетов на этапе сборки:
- Первый пакет содержит код приложения, который был транспилирован, минифицирован и уродован
с использованием современного синтаксиса ECMAScript. Этот пакет содержит меньше полифиллов и поэтому
гораздо меньший размер.
- Второй пакет содержит тот же код, переведенный на старый синтаксис ES5, а также все
необходимыми полифиллами. Само собой разумеется, этот пакет намного больше первого по
по размеру файла, но зато корректно поддерживает старые браузеры.
Функция дифференциальной загрузки может быть настроена путем изменения двух файлов:
- Файл .browserlistrc, в котором перечислены минимальные браузеры, поддерживаемые нашим приложением
- Файл tsconfig.json, определяющий целевую версию ECMAScript, под которую компилируется код
скомпилированный код
Принимая во внимание оба этих параметра, Angular CLI автоматически определит
включать или не включать функциональность дифференциальной загрузки.
Эта стратегия очень эффективна, поскольку она позволяет нашим приложениям Angular поддерживать несколько браузеров, не заставляя
не заставляя современных пользователей извлекать все ненужные пакеты.

# Конфигурационный файл(ы) angular.json
Самое важное различие между ng serve и ng build заключается в том, что последняя является единственной командой.
которая действительно записывает сгенерированные артефакты в выходную папку: эти файлы собираются с помощью
webpack build tool, который можно настроить с помощью конфигурационного файла angular.json.
Выходная папка также задается в этом файле, точнее, в секции projects | [projectName] | architect | build | options | outputPath. В нашем примере это папка dist/[projectName],
это означает, что все сгенерированные артефакты сборки будут развернуты в папках /dist/HealthCheck и /dist/
WorldCities.

# Обновление файла(ов) environment.prod.ts
Еще один файл, о котором нам нужно помнить, - это файл /environments/environment.prod.ts приложений HealthCheck
и WorldCities Angular apps, где мы должны заменить ключевое значение baseUrl - в данный момент оно установлено на https://.
localhost:40443/ - фактическими конечными точками, на которые будут отвечать наши приложения HealthCheckAPI и WorldCitiesAPI
будут отвечать на запросы.
В нашем конкретном сценарии, поскольку мы используем доменные имена третьего уровня домена ryadel.com, нам
необходимо изменить следующим образом:
- https://healthcheck-api-2022.ryadel.com
- https://worldcities-api-2022.ryadel.com
Тем, кто использует другие домены (или любой альтернативный подход), следует обновить приведенные выше значения
в соответствии с их конкретным выбором.

# Автоматическое развертывание
В Angular 8.3.0 появилась новая команда ng deploy, которую можно использовать для развертывания приложения Angular
на одну из доступных производственных платформ благодаря некоторым сторонним сборкам, которые можно установить
с помощью ng add.
Вот список поддерживаемых билдеров на момент написания статьи:
- @angular/fire (Firebase)
- @azure/ng-deploy (MS Azure)
- @zeit/ng-deploy (ZEIT Now)
- @netlify-builder/deploy (Netlify)
- angular-cli-ghpages (GitHub Pages)
- ngx-deploy-npm (NPM)
Хотя опция ng deploy CLI пока не поддерживается Visual Studio, она может быть очень полезна для мгновенного
мгновенно развернуть наше приложение, используя некоторые предустановки, которые можно настроить в секции deploy файла angular.json
файла. Такой секции нет в файле angular.json наших проектов, но она будет автоматически
добавлена, как только один из предыдущих билдеров будет установлен с помощью команды ng add CLI (с соответствующими
соответствующими настройками по умолчанию).
После этого мы готовы приступить к фазе развертывания.

# Развертывание в Windows
В этом разделе мы узнаем, как развернуть наше веб-приложение HealthCheck на сервере Windows 2019 Datacenter edition, размещенном в MS Azure.
Вот что нам предстоит сделать:
- Создайте новую ВМ на MS Azure с помощью шаблона Windows 2022 Datacenter Edition и настройте ее на прием входящих вызовов на TCP-порты 3389 (для Remote Desktop), 80 (для HTTP), 443
(для HTTPS) и 22 (для SSH).
- Настройте ВМ, загрузив и/или установив все необходимые службы и режимы выполнения
для размещения приложения HealthCheck
- Опубликуйте приложение HealthCheck на веб-сервере, который мы только что настроили.
- Настройте IIS для обслуживания приложения надлежащим образом
- Протестируйте приложение HealthCheck с удаленного клиента
Приступаем к работе!

В этом примере развертывания мы создадим совершенно новую виртуальную машину на платформе MS Azure
что требует некоторой дополнительной работы; тем пользователям, у которых уже есть готовый к работе сервер Windows, следует пропустить разделы, связанные с настройкой ВМ, и перейти непосредственно
к темам публикаций.

# Создание виртуальной машины Windows Server в MS Azure
Если мы вспомним наше путешествие по MS Azure в главе 5, Модель данных с Entity Framework Core,
когда мы развертывали там базу данных SQL, мы уже должны быть готовы к тому, что нам предстоит сделать:
- Получить доступ к порталу MS Azure
- Добавить и настроить новую виртуальную машину
- Установить правила безопасности для доступа к ВМ из интернета.
Давайте сделаем это.

# Доступ к порталу MS Azure
Как обычно, начнем со следующего URL-адреса, который приведет нас на веб-сайт MS Azure: https://
azure.microsoft.com/.
Опять же, мы можем либо войти в систему, используя уже существующую учетную запись MS Azure, либо создать новую (возможно.
воспользовавшись бесплатной 30-дневной пробной версией, если мы ее еще не использовали).

Как только мы создали учетную запись, мы можем перейти на https://portal.azure.com/, чтобы получить доступ к порталу администрирования MS
Azure, где мы сможем создать новую ВМ.

# Добавление новой виртуальной машины Windows
Войдя в систему, нажмите на значок виртуальных машин (см. следующий снимок экрана):

![image](https://github.com/artemovsergey/Angular/assets/26972859/857770b5-4a82-4894-a13c-2fcde297d63f)

На следующей странице нажмите Добавить (в левом верхнем углу страницы), чтобы перейти к панели Создать виртуальную машину.
панель создания виртуальной машины.

Панель "Создание виртуальной машины" представляет собой подробный мастер, который позволяет нам настроить новую виртуальную машину
с нуля. Различные параметры конфигурации разделены на несколько панелей, каждая из которых посвящена
определенному набору возможностей, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/395bc1ce-10fa-461c-8bbb-f9e517db7f08)

Стоит отметить, что настройки MS Azure, которые мы будем рассматривать, а также внешний вид и функциональность
различных скриншотов, может измениться в будущем, поскольку Microsoft постоянно добавляет новые функции, переключатели управления
переключателей и других удобств UI/UX в своих мастерах.
Тем не менее, вот краткое описание основных панелей настроек:
- Основы: Тип подписки, имя ВМ, регион развертывания, образ, учетные данные для входа и т. д.
- Диски: Количество и емкость жестких дисков/SDD, которыми будет оснащена ВМ.
- Сеть: Параметры конфигурации, связанные с сетью
- Управление: Функции мониторинга, возможности автоматического отключения, резервного копирования и т. д.
- Дополнительно: Дополнительные настройки, агенты, скрипты, расширения и т.п.
- Теги: Они позволяют использовать некоторые пары имя-значение, которые могут быть полезны для категоризации различных ресурсов MS
Azure ресурсов, которые необходимо установить.
В нашем текущем сценарии нам нужно лишь слегка изменить первые четыре вкладки, оставив остальные
настройки по умолчанию.

На вкладке Основы:
- Группа ресурсов: Используйте ту же группу ресурсов, что и для базы данных SQL (или создайте новую).
- Имя виртуальной машины: используйте NET6-Angular-Windows, HealthCheck или любое другое подходящее имя.
- Регион: Выберите регион, наиболее близкий к нашему географическому положению.
- Параметры доступности: Избыточность инфраструктуры не требуется.
- Изображение: В нашем примере мы будем использовать образ Windows Server 2022 Datacenter по умолчанию;
можете использовать его или выбрать другой.
- Экземпляр Azure Spot: Выберите Да, если вы хотите создать ВМ с помощью функции Azure Spot, которая
которая позволяет нам использовать неиспользуемые мощности Azure со значительной экономией. Однако, поскольку
эти ВМ могут быть вытеснены в любой момент, когда Azure потребуются свободные мощности, мы должны
использовать эту функцию только для краткосрочного тестирования: если мы хотим создать постоянную, производственную ВМ, нам следует выбрать No и создать стандартную машину с оплатой по факту.
- Размер: Стандартный B1ms (1 vCPU, 2 GiB памяти). Не стесняйтесь выбрать другой размер, если вы готовы
потратить больше: B1ms - это машина начального уровня с очень ограниченным набором ресурсов, которых
которой будет достаточно для данного примера развертывания, но которая не будет хорошо работать в производстве.
- Учетная запись администратора: Выберите тип аутентификации Пароль, а затем создайте подходящее
имя пользователя и пароль. Не забудьте записать их в надежном месте, поскольку нам
поскольку эти учетные данные нам обязательно понадобятся для доступа к нашей машине через некоторое время.
На вкладке Диск:
- Тип диска ОС: Выберите стандартный жесткий диск; это самый дешевый вариант.
- Диски данных: Нам не нужно создавать дополнительные диски данных для наших текущих целей

На вкладке Сеть:
- Виртуальная сеть: Если вы создали базу данных SQL, размещенную в Azure, в главе 5 "Модель данных с Entity Framework Core
Entity Framework Core, выберите ту же виртуальную сеть, которая использовалась для нее; в противном случае создайте новую.
- Публичные входящие порты: Выберите Разрешить выбранные порты, затем выберите следующие порты из
списка: HTTP (80), HTTPS (443), SSH (22) и RDP (3389).
На вкладке Управление:
- Мониторинг | Диагностика загрузки: Отключить .
Оставьте все остальные настройки по умолчанию.

После этого нажмите кнопку Обзор + создать, чтобы просмотреть настройки конфигурации и запустить процесс развертывания виртуальной машины.
процесс развертывания.
В конце процесса мы должны увидеть экран, как показано ниже:

![image](https://github.com/artemovsergey/Angular/assets/26972859/a3a2489c-fcd1-4cb6-9446-1f39551b310c)

Отсюда мы можем нажать кнопку Перейти к ресурсу, чтобы получить доступ к панели обзора виртуальной машины.

# Настройка метки DNS-имени
Теперь у нас есть возможность добавить метку DNS-имени для нашей ВМ, которая будет использоваться для генерации уникального
доменного имени пятого уровня в дополнение к ее уникальному цифровому IP-адресу.

Для этого найдите метку DNS-имени на панели обзора виртуальной машины и нажмите на ссылку Настроить, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/7c19d494-ede2-438a-b487-0ca647f26efb)

После создания DNS-имя будет выглядеть так: your-chosen-name.westeurope.cloudapp.azure.
com.

Метка имени DNS - это, по сути, запись A, которая предоставляет "человекочитаемую" публичную
конечной точке вашего сервера VM. Само собой разумеется, что DNS-имя должно быть уникальным
в пределах выбранного региона Azure.
В нашем примере мы будем использовать следующее DNS-имя:
healthcheck-2022.westeurope.cloudapp.azure.com

Настройка метки DNS-имени и получение DNS-имени могут быть полезны, если мы хотим получить доступ к нашему веб-приложению из
приложению из Интернета без необходимости настраивать что-либо на нашей стороне (например, сопоставление хоста с
IP-адрес виртуальной машины или что-то в этом роде). Мы даже можем использовать его для замены одного из "фальшивых" имен хостов.
которое мы планируем поместить в HOSTS-файл нашей локальной машины для HealthCheck и HealthCheckAPI
apps-healthcheck.io или healthcheck-api.io - если захотим.
Прежде чем покинуть вкладку "Обзор", обязательно запишите IP-адрес и DNS-имя виртуальной машины.
поскольку они нам скоро понадобятся.

# Настройка входящих правил безопасности
Перейдите на вкладку Settings | Networking и убедитесь, что на вкладке Inbound port rules указаны маршруты для
публичных входящих портов, которые мы указали при создании виртуальной машины: HTTP (80), HTTPS (443), SSH (22),
и RDP (3389). В том случае, если их здесь нет, нам нужно задать их вручную.
Пока мы здесь, мы также можем воспользоваться возможностью ограничить доступ к некоторым из этих правил вместо того, чтобы оставить их открытыми для публики, в зависимости от наших конкретных потребностей; например, настоятельно рекомендуется
ограничить доступ к входящим правилам SSH и RDP безопасным IP-адресом источника (или диапазоном адресов),
который может быть установлен либо на наш статический IP-адрес, либо на IP-маску нашего провайдера.

Такая настройка гарантирует, что третьи лица не смогут попытаться получить доступ к удаленному рабочему столу или посетить
наше веб-приложение.

ВАЖНО: По соображениям экономии места мы не будем более подробно останавливаться на аспектах безопасности
аспекты, связанные с безопасностью соединений с MS Azure и виртуальными машинами, размещенными в ней.
Открытие портов 3389 и/или 22 для одного IP-адреса - это простое решение, которое хорошо подходит для
для наших тестовых целей, но для производственной среды нам определенно следует перейти на более безопасные
и более надежным протоколам доступа, таким как JIT-доступ, Azure Bastion и/или безопасные SSH-туннели.
Для получения дополнительной информации об этих лучших практиках безопасности читайте следующие руководства:
https://docs.microsoft.com/en-us/azure/security-center/just-in-timeexplained
https://docs.microsoft.com/en-us/azure/bastion/

Независимо от того, как мы будем настраивать эти входящие правила, мы считаем само собой разумеющимся, что оставим открытым
RDP порт 3389 открытым для нашей локальной машины, чтобы мы могли подключаться к нашей ВМ с помощью Remote Desktop.

# Настройка виртуальной машины Windows
Открыв TCP-порт 3389, мы можем запустить встроенный инструмент Remote Desktop Connection с нашей локальной
машины для разработки на базе Windows. Введите публичный IP-адрес виртуальной машины Azure и нажмите Connect, чтобы начать сеанс RDC с нашим удаленным узлом:

![image](https://github.com/artemovsergey/Angular/assets/26972859/b9dd603e-9cd7-4087-9c91-5640e70d8530)

Если правило безопасности для входящих соединений было настроено правильно, мы сможем подключиться к нашему новому рабочему столу
ВМ и настроить нашу ВМ для обслуживания веб-приложения ASP.NET Core и Angular HealthCheck. Для этого необходимо выполнить ряд задач по настройке, которые будут описаны в следующих разделах.
Первым шагом, который мы рассмотрим в следующем разделе, будет установка IIS, гибкого,
безопасного и управляемого HTTP-сервера, который мы будем использовать для размещения нашего приложения ASP.NET Core и Angular
в Интернете.
В целях экономии места мы не будем рассказывать об IIS и изучать его функциональные возможности: мы просто используем
минимальное количество настроек, необходимых для размещения наших приложений. Для получения дополнительной информации об IIS,
посмотрите следующий URL: https://www.iis.net/overview.

# Добавление веб-сервера IIS
Подключившись через Remote Desktop, мы можем зайти в Control Panel | Program and Features | Turn
Включение и выключение функций Windows (или мастер Add Roles and Features Wizard из панели Server Manager), чтобы установить IIS на виртуальную машину, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/3cfcecf7-580f-4b13-b916-c327602827e5)

Из множества доступных ролей выберите Web Server (IIS), как показано на следующем снимке экрана. Убедитесь, что
убедитесь, что установлен флажок Включить инструменты управления, а затем нажмите кнопку Добавить функции, чтобы начать
установку:

![image](https://github.com/artemovsergey/Angular/assets/26972859/b8a693e3-8e72-45f9-92a9-3094c1fd9bf6)

Не нужно ничего менять до конца фазы установки; настройки по умолчанию
отлично подойдут для нашего сценария развертывания.

# Установка пакета ASP.NET Core для хостинга Windows
После установки IIS мы можем приступить к загрузке и установке среды выполнения ASP.NET Core.

Настоятельно рекомендуется устанавливать среду выполнения .NET после установки IIS, поскольку пакет
Пакет выполнит некоторые изменения в настройках конфигурации IIS по умолчанию.
Чтобы загрузить среду выполнения .NET, посетите следующий URL: https://dotnet.microsoft.
com/en-us/download/dotnet/6.0.

Убедитесь, что выбрали пакет установщика ASP.NET Core 6.0.1 Runtime - Windows Hosting Bundle для
Windows x64, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/41f7bfa3-3ac4-4357-90ed-bfecf8bc18be)

Пакет включает в себя среду выполнения .NET, среду выполнения ASP.NET Core и модуль ASP.NET Core IIS,
все, что нам нужно для запуска нашего приложения ASP.NET Core и Angular с нашей виртуальной машины.

# Перезапуск IIS после установки среды выполнения ASP.NET Core
После завершения процесса установки среды выполнения ASP.NET Core рекомендуется выполнить команду stop/start
чтобы перезапустить службу IIS.
Для этого откройте окно Command Prompt с правами администратора и выполните следующие команды
консольные команды:

```
> net stop w3svc /y
> net start w3svc
```
Эти команды позволят IIS уловить изменения в системном пути, внесенные программой установки Windows Hosting
Bundle.

# Публикация HealthCheck и HealthCheckAPI
Теперь мы должны найти способ опубликовать приложение HealthCheck Angular и веб-интерфейс HealthCheckAPI и
развернуть их на нашем сервере.
Что касается приложения Angular, то мы уже знаем, как выполнить первый шаг из главы 12, Прогрессивные веб-приложения.
Приложения: нам нужно открыть командную строку, перейти в корневой каталог проекта и выполнить команду ng build
нам просто нужно скопировать их на нашу новую виртуальную машину.

Простой способ сделать это - использовать функцию совместного использования ресурсов Remote Desktop, которая позволяет нашему
доступ к локальному HDD с удаленного экземпляра... или даже просто вырезать и вставить. Мы можем использовать одну из
этих функций, чтобы скопировать все содержимое папки /build/HealthCheck/ нашей машины разработки
в новую папку C:/inetpub/HealthCheck/, созданную на удаленной ВМ.
Что касается приложения ASP.NET Core, то существует несколько альтернативных вариантов выполнения задачи публикации и
и развертывания, все они доступны из функции профилей публикации.

# Знакомство с профилями публикации Visual Studio
Функция профилей публикации Visual Studio позволяет нам создавать, публиковать, а иногда и развертывать веб-приложение
приложение прямо из графического интерфейса, что значительно упрощает процесс публикации.
Чтобы создать профиль публикации, выберите один из следующих путей:
- Щелкните правой кнопкой мыши проект API в Solution Explorer и выберите Publish
- Выберите Publish {PROJECT NAME} из меню Build
После этого нам будет предложено выбрать одну из нескольких доступных целей публикации, включая:
- Azure
- Реестр контейнеров Docker
- папка
- FTP/FTPS-сервер
- Веб-сервер (IIS)
- Профиль импорта
Учитывая наш конкретный сценарий, мы должны следовать одному из следующих путей:
- Создать профиль публикации папки для публикации нашего приложения в локальной папке на нашей машине разработки,
а затем скопировать файлы на веб-сервер.
- Установить FTP/FTPS-сервер на нашем веб-сервере, а затем настроить профиль публикации FTP.
- Используйте профиль публикации виртуальной машины Azure в Visual Studio
- Использовать профиль публикации веб-сервера (IIS) Visual Studio.
Все вышеперечисленные варианты являются жизнеспособными. Последние два требуют установки некоторых дополнительных компонентов (Web
Deploy) на сервер ВМ: однако, как только мы это сделаем, они будут работать почти полностью автоматически
(развертывание в 1 клик).
Поэтому в следующих разделах мы кратко рассмотрим их все.

# Профиль публикации папок
Вот что нужно сделать, чтобы создать новый профиль публикации папок:
1. Выберите параметр "Папка" (или выберите предыдущий профиль публикации).
2. Укажите путь к папке, в которой будет находиться опубликованное приложение.
3. Нажмите кнопку Создать профиль, чтобы создать профиль
4. Нажмите кнопку Publish, чтобы развернуть нашу внутреннюю часть HealthCheckAPI в выбранной локальной папке. Visual Studio предложит путь, расположенный в подпапке /bin/Release/ приложения, например
/bin/Release/net6.0/publish/; мы можем использовать этот путь или выбрать другую папку по своему усмотрению.
Когда задача публикации будет выполнена, мы можем использовать функцию совместного использования ресурсов RDP, чтобы скопировать все
содержимое папки /bin/Release/net6.0/publish/ нашей машины разработки в новую папку C:/inetpub/
HealthCheckAPI/ - точно так же, как мы это делали с нашим приложением Angular.

# Профиль публикации по FTP
Если наш веб-сервер может принимать FTP (или FTPS) соединения, то подходящим альтернативным способом публикации
нашего проекта - создать профиль публикации на базе FTP, который будет автоматически загружать наш веб-проект на
наш веб-сервер, используя протокол FTP/FTPS.

Чтобы использовать профиль публикации FTP, нам также нужно открыть TCP-порт 21 нашей виртуальной машины (или другой порт не по умолчанию), добавив еще одно правило безопасности для входящих соединений, как мы делали с портами 22, 80, 443 и 3389.
Все, что нам нужно сделать, это связать папку назначения FTP с новым проектом веб-сайта с помощью IIS, и мы сможем
сможем публиковать/обновлять наш сайт в режиме реального времени, поскольку все будет выведено в сеть, как только
как только задача публикации будет выполнена.

Чтобы настроить профиль публикации FTP, выберите IIS, FTP и другие значки, дождитесь появления модального окна, похожего на окно мастера.
появится модальное окно, а затем выберите следующие параметры:
- Метод публикации: Выберите FTP.
- Сервер: Укажите URL-адрес FTP-сервера (IP-адрес или имя домена).
- Путь к сайту: Вставьте целевую папку из корня FTP-сервера, например /HealthCheckAPI/.
- Пассивный режим, имя пользователя, пароль: Установите эти значения в соответствии с настройками нашего FTP-сервера и
предоставленными учетными данными. Активируйте Сохранить пароль, если хотите, чтобы Visual Studio сохранила его, чтобы нам не пришлось
писать его при каждой попытке публикации.
- URL назначения: Этот URL будет автоматически запущен, как только задача публикации успешно завершится, с помощью браузера по умолчанию. Часто целесообразно установить его на базовый домен нашего веб-приложения
например www.our-website-url.com, или оставить его пустым.

После этого нажмите на кнопку Validate Connection, чтобы проверить предыдущие настройки и убедиться, что
что вы можете связаться с сервером по FTP. Если это не так, возможно, стоит провести полномасштабную
проверку сети на наличие брандмауэров, прокси-серверов, антивирусов и другого программного обеспечения, которое может препятствовать установлению FTP-соединения.
установлению FTP-соединения.
Профиль публикации виртуальной машины Azure
Профиль публикации виртуальных машин Azure - это отличный способ обеспечить непрерывную интеграцию и
непрерывной интеграции и непрерывной доставки (CI/CD) DevOps, поскольку он будет выступать в качестве системы сборки (для создания пакетов и других артефактов сборки).
пакетов и других артефактов сборки), либо в качестве системы управления выпуском для развертывания наших изменений.
Чтобы использовать это, выберите опцию Azure Virtual Machine, нажмите кнопку Browse и выберите виртуальную машину, которую мы создали минуту назад (см.
созданную минуту назад (см. следующий снимок экрана):

![image](https://github.com/artemovsergey/Angular/assets/26972859/52a8863c-d2f5-4b03-9e5d-421e872f1b6c)

Однако для этого нам нужно внести некоторые дополнительные изменения в конфигурацию нашей виртуальной машины,
в том числе следующие:
- Установите службу Web Management Service с помощью интерфейса Server Roles, как мы это делали с IIS
- Запустите службу веб-менеджмента и установите режим ее запуска на Automatic
- Установите пакет расширения Web Deploy IIS (доступен на сайте https://www.iis.net/.
downloads/microsoft/web-deploy).
- Откройте TCP-порт 8172 на вкладке "Сеть" виртуальной машины MS Azure, как мы это делали
с 22, 80, 443 и 3389 некоторое время назад.
- Настройте глобально уникальное DNS-имя для виртуальной машины (как объяснялось в разделе Настройка DNS-имени
в разделе Настройка DNS-имени)
По соображениям экономии места мы не будем рассматривать эти настройки. Однако для получения дополнительной информации о предыдущих задачах ознакомьтесь со следующим руководством: https://github.com/aspnet/Tooling/blob/.
AspNetVMs/docs/create-asp-net-vm-with-webdeploy.md.
После выполнения этих настроек мы сможем опубликовать наше веб-приложение на ВМ
бесшовной и прозрачной манере.

# Настройка IIS
Независимо от того, какой метод публикации мы использовали, на нашем удаленном сервере VM уже должны быть следующие папки
следующие папки:
- C:/inetpub/HealthCheck/ - с файлами нашего приложения Angular в комплекте
- C:/inetpub/HealthCheckAPI/- с опубликованными файлами ASP.NET Core Web API
Сейчас самое время создать (или отредактировать) файл appsettings.Production.json нашего приложения HealthCheckAPI.
следуя рекомендациям, о которых мы рассказали ранее.
Что касается файла appsettings.Development.json, мы можем просто удалить его, поскольку нам, скорее всего, никогда не понадобится
запускать наше приложение в среде разработки на этом сервере VM.

После этого нам нужно настроить IIS, чтобы сделать эти два приложения доступными во Всемирной паутине. Чтобы
для этого нам нужно добавить две записи веб-сайта IIS:
- HealthCheck для приложения Angular
- HealthCheckAPI - для приложения ASP.NET Core.
Начнем с приложения Angular.

# Добавление записи веб-сайта HealthCheck
На главной странице IIS Manager разверните корневой узел, чтобы показать папку Sites, затем щелкните ее правой кнопкой мыши
и выберите опцию Добавить веб-сайт, чтобы создать новый веб-сайт.

Заполните модальное окно "Добавить сайт", как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/5ab272fc-6693-4f49-ae5c-2892c178726a)

Вот краткое описание наиболее важных настроек (и то, как мы рекомендуем их устанавливать для нашей конкретной
цели):
- Имя сайта: имя, которое вы хотите дать своему сайту; в нашем примере мы используем HealthCheck.
- Физический путь: C:\inetpub\HealthCheck (путь, куда мы скопировали собранные файлы приложения Angular).
- Тип привязки: https.
- IP-адрес: All Unassigned.
- Порт: 443.

- Имя хоста: Это конечная точка, на которую будет отвечать приложение Angular: другими словами, основная
точка входа для наших конечных пользователей. На скриншоте выше мы использовали healthcheck-2022.ryadel.
com, но вам, очевидно, нужно использовать реальное имя хоста.
- Требовать указания имени сервера: Да.
- SSL-сертификат: В нашем сценарии мы используем наш сертификат TLS/SSL wildcard: если у вас его нет.
вы можете выбрать TenantEncryptionCert, предоставляемый Azure, или использовать самоподписанный
TLS/SSL-сертификат (см. ниже).
- Запустить веб-сайт немедленно: Да.
После этого нажмите OK, чтобы добавить новый веб-сайт. Новая запись появится в древовидном представлении справа
в папке "Сайты".

# Добавление записи веб-сайта HealthCheckAPI
Снова щелкните правой кнопкой мыши на папке Sites, затем щелкните ее правой кнопкой мыши и выберите опцию Add Website, чтобы создать
еще один веб-сайт.
Повторите те же шаги, что и раньше, со следующими отличиями:
- Название сайта: В нашем примере мы используем HealthCheckAPI.
- Физический путь: C:\inetpub\HealthCheckAPI (путь, куда мы скопировали опубликованные файлы
нашего приложения ASP.NET Core).
- Имя хоста: Это конечная точка, на которую будет отвечать ASP.NET Core Web API: другими словами,
конечная точка, которую мы должны поместить в файл environment.prod.ts приложения Angular. Поместите выбранное вами
имя хоста.
После этого нажмите OK, чтобы добавить новый веб-сайт. Теперь у нас должно быть два сайта в папке Sites
HealthCities и HealthCitiesAPI, каждый из которых настроен на работу с разными доменными именами.
Прежде чем продолжить, стоит сказать пару слов о SSL-сертификатах.

# Замечание о сертификатах TLS/SSL
Поскольку наши приложения должны обслуживаться по протоколу HTTPS, при создании записей веб-сайтов в IIS мы
необходимо было указать сертификат TLS/SSL для обоих сайтов. Для простоты мы предположили, что у нас
уже есть действующий TLS/SSL-сертификат, совместимый с используемыми именами хостов. Если у нас нет
их, мы можем либо:
- Приобрести и установить сертификат TLS/SSL у стороннего реселлера
- Получить бесплатный сертификат TLS/SSL с помощью некоммерческого центра сертификации, например Let's Encrypt.
- Использовать сертификат арендатора MS Azure, автоматически сгенерированный MS Azure при создании нашей ВМ
- Создать самоподписанный сертификат, используя руководство ниже
Первые два способа, скорее всего, подойдут для любого нетестового сценария. Другие альтернативы
подойдут при выполнении начальных тестов развертывания, поскольку они обеспечивают более быструю (и беззатратную) альтернативу для достижения нашей цели: именно поэтому мы будем использовать их в нашем примере.

Однако у сертификата, созданного в Azure или подписанного самостоятельно, есть следующие недостатки:
- Все браузеры (и антивирусы с фильтрами веб-защиты) будут выдавать типичные предупреждения SSL
и сообщения "небезопасный веб-сайт", которые нам придется вручную подтверждать/принимать/пропускать.
- Мы не сможем правильно протестировать большинство функций PWA в нашем приложении, потому что служба
регистрация рабочего будет неудачной

В следующем разделе мы кратко рассмотрим, как создать самоподписанный SSL-сертификат, который можно использовать
вместо сертификатов MS Azure.

# Создание самоподписанного SSL-сертификата
Чтобы создать самоподписанный SSL-сертификат, подключитесь к ВМ с помощью Remote Desktop и выполните следующие действия.
следующие шаги:
1. Откройте настольное приложение IIS Manager, выберите корневой узел в древовидном представлении слева, а затем
дважды щелкните значок "Сертификаты сервера", как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/8469c2d5-6e65-4cfb-bd4c-a3565db15549)

2. Оказавшись на панели сертификатов сервера, щелкните ссылку Create Self-Signed Certificate (Создать самоподписанный сертификат) в колонке Actions (Действия) справа.

3. Появится модальное окно (см. следующий снимок экрана), в котором нам будет предложено указать
дружественное имя для сертификата. Выберите дружественное имя для сертификата, выберите Личное
хранилище сертификатов, а затем нажмите OK, чтобы создать самоподписанный сертификат:

![image](https://github.com/artemovsergey/Angular/assets/26972859/ea402cba-c358-45ec-ae41-219a041d1b62)

В приведенном выше примере мы используем дружественное имя healthcheck.io для сертификата, но мы вольны
использовать любое имя, которое нам нравится: мы не используем конкретное доменное имя, поскольку, скорее всего, будем использовать этот
сертификат для всех сайтов и служб, которые не могут полагаться на сертификат, подписанный ЦС.
После этого мы сможем назначить наш новый самоподписанный SSL-сертификат для всех записей нашего сайта, заменив им сертификат MS Azure.

# Настройка пула приложений IIS
Как вы, возможно, уже знаете, служба IIS запускает различные настроенные веб-сайты под управлением одного или нескольких
пулов приложений. Каждый настроенный пул приложений порождает специальный процесс w3wp.exe Windows.
который будет использоваться для обслуживания всех веб-сайтов, настроенных на его использование.
В зависимости от требований к публикации различных веб-сайтов, которые нам нужно разместить, мы можем запустить все
веб-сайты в нескольких пулах приложений (или даже в одном) или каждый из них в своем собственном пуле приложений.
Само собой разумеется, что все веб-сайты, использующие один и тот же пул приложений, будут также совместно использовать различные
настройки, такие как использование памяти, режим конвейера, идентификация и таймаут простоя.
В нашем конкретном сценарии, когда мы создавали веб-сайты HealthCheck и HealthCheckAPI в предыдущем разделе, мы решили создать выделенный пул приложений с тем же именем - это также поведение по умолчанию в IIS.
IIS по умолчанию. Поэтому, чтобы настроить параметры пула приложений сайта, нам нужно
щелкнуть на папке Application Pools в древовидном представлении слева, а затем дважды щелкнуть на каждом
на каждой записи веб-сайта на панели списка Application Pools, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/637a45a2-ba40-4092-a671-c851978c8f4e)

В модальном окне Edit Application Pool выберите следующие настройки, как показано на предыдущем
скриншоте:
- Версия .NET CLR: No Managed Code
- Режим управляемого конвейера: Integrated .
Вам может быть интересно, почему мы также выбираем No Managed Code для пула приложений API,
ведь мы явно используем ASP.NET Core CLR. Ответ прост: поскольку ASP.NET Core работает в
отдельном процессе IIS, нет необходимости устанавливать версию .NET CLR в IIS.

Настройка IIS почти завершена. Однако прежде чем мы сможем протестировать то, что сделали, нам нужно
выполнить последнюю задачу: добавить расширение файла .webmanifest в список поддерживаемых IIS типов MIME.

# Добавление MIME-типа .webmanifest
Согласно настройкам по умолчанию, IIS не обслуживает файлы с расширением, которое не имеет MIME
карта, связанная с ним. К сожалению, расширение .webmanifest, которое мы использовали в главе 12,
Прогрессивные веб-приложения, для нашего файла манифеста PWA - не связано с картой MIME, а это значит, что
этот файл не будет отправлен в браузер.

Чтобы устранить эту проблему, нужно выполнить следующие задачи из инструмента IIS Manager:
1. В древовидном представлении слева выберите корневой узел сервера или веб-сайт HealthCheck,
в зависимости от того, хотим ли мы добавить новое отображение на все сайты или только на сайт нашего приложения Angular
В нашем сценарии оба варианта будут работать, но мы предлагаем добавить отображение на
на все сайты, поскольку это не вызовет серьезных проблем с безопасностью.
2. Выберите MIME Types из списка опций в правой части окна.
3. После этого в меню справа выберите Добавить.
4. В открывшемся диалоговом окне введите .webmanifest в поле расширения имени файла и application/
manifest+json в поле MIME-тип, как показано на скриншоте ниже:

![image](https://github.com/artemovsergey/Angular/assets/26972859/0a40222c-da31-449e-b5a7-d94b508b2068)

Вот и все: теперь мы готовы проверить наше приложение HealthCheck Angular и HealthCheckAPI ASP.NET Core
Web API и убедиться, что они по-прежнему способны работать вместе, как это было на нашей машине разработки.

# Тестирование HealthCheck и HealthCheckAPI
Теперь наше веб-приложение должно быть готово к приему HTTP-запросов; нам нужно только убедиться, что
удаленные клиенты смогут получить к нему доступ, включая машину, которую мы хотим использовать для проведения нашего первого
тест соединения.

Более конкретно, то, что нам нужно сделать, зависит от того, как мы настроили имя хоста нашего IIS
веб-сайтов:
- Если мы использовали реальные доменные имена (или IP-адреса, или DNS-имена), нам просто нужно установить
новые записи DNS и/или подождать, пока они распространятся.
- Если мы использовали "фальшивые" имена хостов, нам нужно сопоставить их с IP-адресом удаленного сервера виртуальной машины
IP-адресу сервера удаленной виртуальной машины в файле HOSTS локальной машины, как объясняется в разделе Настройка файла HOSTS выше
выше
Как только конечные точки обоих наших сайтов будут доступны с нашей машины, мы можем приступить к тестированию.

# Тестирование приложения
Теперь мы можем запустить наш любимый веб-браузер на базе Chromium и вызвать конечную точку приложения Angular
конечную точку приложения Angular, которую мы настроили в самом начале.

Браузер на базе Chromium, такой как Google Chrome или Microsoft Edge, позволит нам
немедленно проверить файл манифеста веб-приложения и рабочий сервис, точно так же, как мы
как в случае с тестом "локальной" публикации, который мы проводили в главе 12, Прогрессивные веб-приложения.

Если мы все сделали правильно, мы должны увидеть наше веб-приложение HealthCheck во всей его красе:

![image](https://github.com/artemovsergey/Angular/assets/26972859/d57db705-7272-44bf-b262-f665893350d2)

Кроме домашнего вида, мы также должны видеть следующее:
- Файл манифеста приложения (со всеми иконками HC) в панели Application | Manifest консоли разработки браузера.
- Правильно зарегистрированный рабочий сервис в панели Application | Service Workers консоли разработки браузера.
консоли разработки браузера
- Значки "Отправить эту страницу" и "Установить" в правой части адресной строки браузера.
Чтобы увидеть эти панели, не забудьте нажать Shift + Ctrl + J, чтобы привести консоль разработки в
вид.
Теперь мы можем установить приложение и проверить/отметить его автономный статус, чтобы проверить поведение работника службы, как мы это делали в главе 12 "Прогрессивные веб-приложения", когда тестировали наше опубликованное приложение
из стандартного отладочного запуска Visual Studio; если мы все сделали правильно, все должно работать и
все должно работать и вести себя одинаково.
На этом мы завершили наше путешествие по установке Windows; наши веб-приложения HealthCheck и HealthCheckAPI
достигли своей конечной цели.
В следующем разделе мы рассмотрим, как развернуть веб-приложения WorldCities и WorldCitiesAPI на
совершенно другой машине.

# Развертывание на Linux
В этом разделе мы узнаем, как развернуть веб-приложение WorldCities на сервере Linux CentOS
8, размещенном на сервере MS Azure.
Точнее, вот что нам предстоит сделать:
- Создадим новую ВМ в MS Azure, используя шаблон 8.2 на базе CentOS.
- Настройте ВМ на прием входящих вызовов на TCP-порты 22 (для SSH), 80 (для HTTP) и 443
(для HTTPS), а также настройте модель хостинга Nginx + Kestrel edge-origin.
- Опубликуйте приложение WorldCities на веб-сервере, который мы только что настроили.
- Протестируйте приложение WorldCities с удаленного клиента.
Приступаем к работе!

Стоит отметить, что шаблон на базе CentOS, который мы будем использовать в этом примере развертывания
можно легко заменить с небольшими изменениями любым другим шаблоном Linux VM
доступным в MS Azure: на самом деле, среда выполнения ASP.NET Core Linux хорошо работает
с большинством дистрибутивов Linux на базе Debian и RPM, с небольшими отличиями.
в основном связанных с их системами управления пакетами.
Излишне говорить, что те, у кого уже есть готовый к работе Linux-сервер, могут
пропустить разделы, связанные с настройкой виртуальной машины, и перейти непосредственно к последующим темам публикации.

# Создание виртуальной машины Linux CentOS в MS Azure
И снова нам нужно выполнить следующие шаги:
- Зайдите на портал MS Azure
- Добавьте и настройте новую ВМ
- Установить входящие правила безопасности для доступа к ВМ из интернета
Однако, поскольку мы уже объясняли процесс создания ВМ в MS Azure с помощью Windows Server ранее
в этой главе, мы кратко изложим все общие задачи и не будем повторять
одни и те же скриншоты.

Те, кому нужны дополнительные объяснения относительно различных необходимых шагов, могут ознакомиться с
раздел Создание виртуальной машины Windows Server в MS Azure.

Давайте еще раз вернемся к MS Azure!
Добавление новой виртуальной машины Linux
И снова нам нужно войти в MS Azure с помощью нашей (существующей или новой) учетной записи и получить доступ к панели администрирования портала MS
Azure portal administration dashboard.
Сразу после этого мы можем щелкнуть на значке виртуальной машины и нажать Добавить, чтобы перейти к панели Создать виртуальную машину.
и введите следующие параметры.
На вкладке Основы:
- Группа ресурсов: Используйте ту же группу ресурсов, что и для базы данных SQL (это обязательно.
если только наша база данных не находится там).
- Имя виртуальной машины: Используйте NET6-Angular-Linux, WorldCities или любое другое подходящее имя.
- Регион: Выберите регион, наиболее близкий к нашему географическому положению.
- Параметры доступности: Избыточность инфраструктуры не требуется.
- Изображение: В нашем примере мы будем использовать образ CentOS 8.3 Free от Cognosys (см. ниже),
который предоставляется бесплатно; в качестве альтернативы вы можете выбрать любой другой шаблон ВМ на базе Linux, если вы готовы и можете адаптировать следующие инструкции в соответствии с
(возможно, незначительных) различий между разными дистрибутивами Linux.
- Экземпляр Azure Spot: Опять же, выберите "Да" для экземпляра Azure Spot или "Нет" для стандартного экземпляра с оплатой по факту.
- Размер: Стандартный B1ms (1 vcpu, 2 GiB памяти): Не стесняйтесь выбрать другой размер, если вы готовы
B1ms - это машина начального уровня с очень ограниченным набором ресурсов, которых
которой будет достаточно для данного примера развертывания, но которая не будет хорошо работать в производстве.
- Учетная запись администратора: Выберите тип аутентификации Пароль, а затем создайте подходящее
имя пользователя и пароль. Не забудьте записать их в надежном месте, поскольку нам
поскольку через некоторое время нам обязательно понадобятся эти учетные данные для доступа к нашей машине.

На вкладке Диск:
- Тип диска ОС: Выберите Standard HDD; это самый дешевый вариант. Само собой разумеется.
что тем, кто хочет создать производственную среду (или готов заплатить немного больше), следует выбрать более быстрый вариант, например Standard или Premium SSD.
баксов) должны выбрать более быстрый вариант, например Standard или Premium SSD.
- Диски данных: ВМ Azure Linux поставляются с временным диском и диском ОС, которых вполне достаточно.
достаточно для наших целей; опять же, те, кто хочет создать производственную среду
могут (и должны) добавить сюда дополнительное хранилище.
На вкладке Сеть:
- Виртуальная сеть: Выберите ту же VNet, которая используется для базы данных SQL (или создайте новую).
- Публичные входящие порты: Если мастер позволяет это сделать (в зависимости от выбранного образа ОС), выберите
Разрешить выбранные порты, затем выберите следующие порты из списка: HTTP (80), HTTPS (443),
SSH (22)
На вкладке Управление:
- Мониторинг | Диагностика загрузки: Выключить .
После этого нажмите кнопку Review + create, чтобы просмотреть настройки конфигурации и запустить процесс развертывания виртуальной машины.
процесс развертывания.
После завершения развертывания мы можем нажать кнопку Перейти к ресурсу, чтобы получить доступ к панели обзора виртуальной машины
панель обзора виртуальной машины.

# Настройка метки имени DNS
И снова у нас есть возможность добавить метку DNS-имени к нашей виртуальной машине и сгенерировать уникальное доменное имя пятого уровня для удобного доступа к ней. Для этого нам нужно найти метку DNS-имени
на панели обзора виртуальной машины, щелкнуть на ссылке "Настроить" и выполнить действия, описанные выше для виртуальной машины Windows.
описанные выше для виртуальной машины Windows.
Прежде чем продолжить, запишите DNS-имя и IP-адрес машины, поскольку они нам, скорее всего, понадобятся
они нам понадобятся позже.

# Настройка входящих правил безопасности
Перейдите на вкладку Настройки | Сеть и обратите внимание на публичный IP-адрес машины. Затем проверьте
наличие следующих правил безопасности входящих соединений и добавьте их, если они еще не присутствуют:
- TCP-порт 22, чтобы мы могли получить доступ к машине с помощью протокола Secure Shell (также известного как SSH).
известный как SSH)
- TCP-порты 80 и 443, чтобы получить доступ к HTTP-серверу (и нашему веб-приложению WorldCities) из
Интернета с помощью SSL
Опять же, если вы хотите повысить уровень безопасности ВМ, обязательно ограничьте доступ к этим входящим правилам безопасным IP-адресом источника (или диапазоном адресов), который может быть установлен либо на наш статический IP-адрес
адрес или IP-маску нашего провайдера.


# Настройка виртуальной машины Linux
Теперь мы можем использовать протокол SSH для доступа к нашей новой виртуальной машине Linux VM и выполнить два разных (но оба
необходимых) набора задач:
- Установите и настройте ВМ, установив различные необходимые пакеты (среда выполнения ASP.NET Core
среда выполнения ASP.NET Core, HTTP-сервер Nginx и т. п.)
- Собрать, опубликовать и развернуть проекты WorldCities и WorldCitiesAPI с помощью Angular CLI
и профиля публикации Visual Studio, как мы делали это для Windows VM.
Для выполнения первого набора задач мы будем использовать PuTTy, бесплатный SSH-клиент для Windows, который можно использовать
для удаленного доступа к консоли Linux-машины. Что касается задач развертывания, то мы будем решать их с помощью
Secure Copy (aka SCP), инструмента командной строки Windows, который позволяет копировать файлы с (локальной)
Windows-системы на удаленную Linux-машину.

# Подключение к виртуальной машине
После установки запустите PuTTy и введите публичный IP-адрес (или DNS-имя) ВМ, как показано на
как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/8d02746f-b13f-4d99-8e52-320b9138ccc5)

После этого нажмите кнопку Открыть, чтобы запустить удаленное соединение.
Нам будет предложено принять открытый SSH-ключ. После принятия мы сможем аутентифицировать себя
с помощью имени пользователя и пароля, указанных некоторое время назад в мастере настройки виртуальной машины на портале MS Azure
мастера настройки:

![image](https://github.com/artemovsergey/Angular/assets/26972859/ccd9834d-4b1f-4255-a50c-53eddf31fff5)

После подключения мы сможем выполнять команды терминала на удаленной ВМ, чтобы установить и настроить
ее в соответствии с нашими потребностями.
Шаги настройки, описанные в следующих разделах, подходят на данный момент, но могут измениться
в будущем после выхода новых версий .NET и/или CentOS. Чтобы получить актуальную информацию, ознакомьтесь
следующее руководство: https://docs.microsoft.com/en-us/dotnet/core/install/linux-centos.

# Установка среды выполнения ASP.NET Core
После успешного входа в терминал Linux VM мы можем приступить к настройке удаленной
систему, чтобы она могла запускать (и размещать) приложения ASP.NET Core. Чтобы добиться этого, первое, что нужно сделать
это загрузить и установить среду выполнения ASP.NET Core.
Однако прежде чем это сделать, необходимо выполнить следующие шаги:
- Зарегистрировать ключ Microsoft
- Зарегистрировать репозиторий продукта
- Установить необходимые зависимости
Эти шаги необходимо выполнить один раз для каждой машины Linux. К счастью, все они могут быть выполнены с помощью
следующей команды:

```
$ sudo rpm -Uvh https://packages.microsoft.com/config/centos/8/packagesmicrosoft-prod.rpm
```
Как только это будет сделано, мы сможем установить среду выполнения ASP.NET Core 6.0 следующим образом:

```
$ sudo dnf install aspnetcore-runtime-6.0
```

Предыдущая команда несколько раз запросит подтверждение и, скорее всего, займет некоторое время
для завершения.
В качестве альтернативы, если мы не хотим устанавливать среду выполнения ASP.NET Core на Linux-сервер, мы можем опубликовать приложение как SCD, как объясняется в первом разделе этой главы.
После этого мы можем перейти к следующему шагу: установке веб-сервера.

# Установка Nginx
Следующее, что нам нужно сделать, - это установить серверный пакет Nginx. Для тех, кто не знает
Nginx - это бесплатный высокопроизводительный HTTP-сервер с открытым исходным кодом, балансировщик нагрузки и обратный прокси.
используемый миллионами: именно этот HTTP-сервер мы будем использовать в Linux для обслуживания нашего веб-приложения путем
обратного проксирования сервиса Kestrel.

В феврале 2020 года, по оценкам Netcraft, Nginx обслуживал 36,48 % всех активных веб-сайтов.
что ставит его на первое место по сравнению с Apache (24,51 %): однако, по данным W3Techs,
Apache занимал первое место с показателем 40,1 %, а Nginx - второе с показателем 31,8 % примерно в тот же период.
период. Тем не менее, мы будем использовать Nginx, поскольку он имеет модульную, событийно-ориентированную,
асинхронная однопоточная архитектура, которая хорошо масштабируется на общем серверном оборудовании
и многопроцессорных системах, что делает его идеальным партнером для веб-приложения ASP.NET Core
размещенного на Linux.

В предыдущих версиях CentOS, прежде чем сделать это, мы должны были добавить репозиторий EPEL, который
который был необходим для того, чтобы YUM нашел пакет Nginx для установки:

```
$ sudo dnf install epel-release
```
Однако, начиная с CentOS 8, Nginx можно установить без предварительных шагов следующим образом:

```
$ sudo dnf install nginx
```
Теперь нам нужно настроить Nginx на автоматический запуск при каждом запуске (или перезапуске) виртуальной машины.

# Запуск Nginx
Когда мы устанавливаем IIS на Windows, служба запускается автоматически и по умолчанию настроена на
автоматический тип запуска по умолчанию. И наоборот, Nginx не запускается сам по себе и не будет выполняться
автоматически при запуске

Чтобы запустить Nginx, выполните следующую команду:
```
$ sudo systemctl start nginx
```
Чтобы настроить автоматический запуск Nginx при старте системы, выполните следующую команду:
```
$ sudo systemctl enable nginx
```
После применения этих настроек целесообразно перезагрузить Linux-машину, чтобы убедиться, что все
все настроенные параметры будут применены при перезагрузке. Перезагрузку можно выполнить с помощью следующей команды:
```
$ sudo reboot
```
Теперь мы можем настроить TCP и HTTP уровни машины.

# Проверка HTTP-соединения
Шаблон MS Azure VM на базе CentOS, который мы использовали в этом сценарии развертывания, не поставляется
с локальным брандмауэром, блокирующим TCP-порты 80 и/или 443. Поэтому, как только Nginx будет запущен, мы сможем правильно подключиться к нему, введя публичный IP-адрес (или DNS-имя) ВМ
в адресной строке браузера с нашей машины разработки.
Если мы все сделали правильно, мы должны увидеть страницу приветствия Nginx, как показано на следующем
скриншот:

![image](https://github.com/artemovsergey/Angular/assets/26972859/16530c4c-a98b-4697-9496-739561817f81)

Если мы видим предыдущий ответ, это означает, что, скорее всего, нам не нужно беспокоиться о брандмауэре, поэтому
мы можем пропустить этот раздел и перейти к следующему. И наоборот, если соединение не может быть
установить соединение, нам, возможно, придется выполнить дополнительные действия, чтобы открыть 80 и 443 TCP-порты виртуальной машины.

Прежде чем изменять правила брандмауэра ВМ, стоит тщательно проверить наличие правил безопасности TCP 80 и
443 правила безопасности входящих соединений, которые мы должны были установить на сайте администрирования портала MS Azure
как объясняется в разделе Настройка правил безопасности входящих соединений.

# Открытие портов 80 и 443 TCP
В зависимости от выбранного шаблона Linux может потребоваться изменить настройки локального брандмауэра
чтобы разрешить входящий трафик для портов 80 и 443 TCP. Команды, необходимые для этого, могут отличаться,
в зависимости от встроенного уровня абстракции брандмауэра, поставляемого с дистрибутивами Linux.
В Linux брандмауэр на базе ядра управляется iptables, однако в большинстве современных дистрибутивов
обычно используют либо уровень абстракции firewalld (CentOS, RHEL), либо ufw (Ubuntu) для настройки
настройки iptables.

# В двух словах, и firewalld, и ufw - это инструменты управления брандмауэром, которые могут использоваться
системные администраторы для настройки функций брандмауэра с помощью управляемого подхода. Мы
можно считать их внешними интерфейсами для сетевых внутренностей ядра Linux.

В Linux-шаблоне VM Azure на базе CentOS присутствует firewalld, но обычно он отключен (хотя
его можно запустить и/или включить, чтобы он автоматически запускался при каждом запуске); однако, если мы используем
другой шаблон/VM/дистрибутив Linux, будет полезно потратить пару минут на изучение того.
как правильно настроить эти инструменты.

# firewalld
Вот команда для проверки того, установлен ли firewalld:
```
$ sudo firewall-cmd --state
```
Если команда выдает результат, отличный от "не запущено" или "команда не найдена", это означает, что
инструмент установлен и активен. Поэтому нам нужно выполнить следующие команды firewalld, чтобы
открыть TCP-порты 80 и 443:
```
$ sudo firewall-cmd --permanent --add-port=80/tcp
$ sudo firewall-cmd --permanent --add-port=443/tcp
$ sudo firewall-cmd --reload
```
Команда --reload необходима для немедленного применения настроек firewalld без необходимости
перезагрузки.

# ufw
Вот команда для проверки того, запущен ли ufw:
```
$ sudo ufw status
```
Если предыдущая команда возвращает что-то кроме "Команда не найдена", это означает, что инструмент
установлен и работает.
Вот необходимая команда терминала ufw для открытия TCP-портов 80 и 443:
```
$ sudo ufw allow 80/tcp
$ sudo ufw allow 443/tcp
```

После выполнения этих команд мы должны подключиться к HTTP-серверу Nginx с машины разработчика и получить страницу ответа, показанную на предыдущем скриншоте.

# Публикация WorldCities и WorldCitiesAPI
Теперь мы можем опубликовать проекты WorldCities и WorldCitiesAPI и развернуть их на сервере Linux
VM-сервер.

# Создание приложения Angular
Что касается приложения Angular, мы можем сгенерировать производственный пакет в папке /dist/ с помощью команды ng build
в Angular CLI, как мы это делали в начале работы с приложением HealthCheck.
Перед этим обязательно проверьте файл /environments/environment.prod.ts, чтобы убедиться, что ключ
baseUrl установлена публичная конечная точка, которую мы планируем использовать для нашего WorldCitiesAPI ASP.NET Core
WebAPI. В нашем текущем сценарии мы будем использовать следующий URL:

```ts
export const environment = {
 production: true,
 baseUrl: "https://worldcities-api-2022.ryadel.com/"
};
```

Опять же, не забудьте изменить указанное выше значение в зависимости от выбранного подхода к определению публичных конечных точек.
Это все для приложения WorldCities Angular; а вот его аналог WorldCitiesAPI нуждается в некоторой
дополнительной работы.

# Создание приложения WorldCitiesAPI
Чтобы опубликовать веб-приложение WorldCitiesAPI, нам нужно создать еще один профиль публикации Visual Studio и
затем выполнить его, чтобы собрать производственные файлы в папке /bin/Release/net6.0/publish/, которые мы должны будем загрузить на сервер ВМ.
загрузим на сервер VM, как мы это делали с HealthCheckAPI.
Однако перед этим нам нужно убедиться, что наше веб-приложение правильно настроено на
обслуживаться через обратный прокси-сервер и сможет получить доступ к производственной базе данных.
Чтобы сделать первое, нам нужно использовать Forwarded Headers Middleware из Microsoft.
AspNetCore.HttpOverrides.
Когда HTTPS-запросы проксируются через HTTP с помощью техники edge-origin, такой как та, которую мы
с помощью Kestrel и Nginx, IP-адрес клиента, а также оригинальная схема
(HTTPS), теряется между двумя участниками. Поэтому мы должны найти способ передать эту информацию. Если
мы не сделаем этого, то можем столкнуться с различными проблемами при выполнении перенаправления маршрутизации, аутентификации,
ограничений или грантов на основе IP-адресов и так далее.
Наиболее удобным способом пересылки этих данных является использование заголовков HTTP: точнее, использование
X-Forwarded-For (IP-адрес клиента), X-Forwarded-Proto (схема отправления) и X-Forwarded-Host
(значение поля заголовка хоста).

Встроенное ПО Forwarded Headers Middleware, предоставляемое ASP.NET Core, выполняет эту задачу, считывая
эти заголовки и заполняя соответствующие поля в HttpContext веб-приложения.

Пока мы там, нам также нужно правильно проверить строку подключения к базе данных SQL, которую мы установили
в главе 5, Модель данных с Entity Framework Core, чтобы убедиться, что она по-прежнему доступна для
Linux VM (или изменить ее соответствующим образом). В следующих двух разделах мы рассмотрим обе эти проблемы.


# Добавление промежуточного ПО для переадресованных заголовков
Чтобы добавить промежуточное ПО Forwarded Headers Middleware, откройте файл Program.cs в WorldCitiesAPI и добавьте следующие выделенные строки к существующему коду
следующие выделенные строки в существующий код:

```Csharp
using Microsoft.AspNetCore.HttpOverrides;
// ...
app.UseHttpsRedirection();
// Invoke the UseForwardedHeaders middleware and configure it
// to forward the X-Forwarded-For and X-Forwarded-Proto headers.
// NOTE: This must be put BEFORE calling UseAuthentication
// and other authentication scheme middlewares.
app.UseForwardedHeaders(new ForwardedHeadersOptions
{
 ForwardedHeaders = ForwardedHeaders.XForwardedFor
 | ForwardedHeaders.XForwardedProto
});
app.UseAuthentication();
app.UseAuthorization();
```
Как мы видим, мы указываем промежуточному ПО пересылать заголовки X-Forwarded-For и X-Forwarded-Proto
тем самым гарантируя, что перенаправленные URI и другие политики безопасности будут работать правильно.

ВАЖНО: Как написано в комментариях, это промежуточное ПО должно быть установлено перед вызовом
UseAuthentication или других промежуточных модулей схемы аутентификации.

Теперь мы можем перейти к следующему шагу: добавлению строки подключения, которая позволит нам подключиться к
производственной базе данных.

# Проверка строки подключения к базе данных
В Проводнике решений откройте файл secrets.json и проверьте строку подключения, которую мы настроили
в главе 5, Модель данных с Entity Framework Core, которая с тех пор безупречно работает на нашей машине для разработки.
машины с тех пор. Мы должны быть уверены, что такая строка подключения будет работать и на нашей виртуальной машине Linux.
Если база данных SQL размещена в MS Azure или на общедоступном сервере, нам не придется ничего делать;
Однако в случае, когда мы используем локальный экземпляр базы данных SQL, установленный на нашей машине для разработки
машине, нам нужно выбрать один из следующих вариантов:
1. Переместить и/или скопировать базу данных WorldCities SQL в MS Azure
2. Установить локальный экземпляр SQL Server Express (или Development) на ВМ CentOS сразу после ее создания
3. Настройте входящее правило для пользовательского локального (или удаленного) экземпляра SQL Server Express (или Development)
который мы настраивали в главе 5, Модель данных с Entity Framework Core, возможно, ограничивая
внешний доступ только к публичному IP-адресу новой виртуальной машины.
Для варианта № 1 щелкните правой кнопкой мыши локальный экземпляр базы данных SQL и выберите Задачи | Развернуть базу данных в MS
Azure SQL Database; дополнительные сведения см. в главе 5 "Модель данных с Entity Framework Core".
Для варианта № 2 ознакомьтесь со следующим руководством по установке SQL Server Linux: https://docs.microsoft.
com/en-us/sql/linux/sql-server-linux-setup.
Для варианта № 3 посмотрите следующий URL-адрес: https://docs.microsoft.com/en-us/sql/sql-server/.
install/configure-the-windows-firewall-to-allow-sql-server-access.
Независимо от выбранного нами варианта, в конечном итоге мы получим строку подключения, которая
которая позволит нам подключиться к производственной базе данных. Затем мы можем создать новый файл appsettings.Production.
json на сервере VM и добавить туда строку подключения, а также ключи JwtSettings и
AllowedCORS, как объяснялось ранее в этой главе, в разделе Обновление файла appsettings.Production.
json-файла(ов).

Пример файла appsettings.Production.json для WorldCitiesAPI был добавлен -
только в справочных целях в репозиторий GitHub для этой главы. Убедитесь, что вы не делаете
этого в своих проектах, не являющихся образцами, и/или при работе с реальными учетными данными базы данных,
так как это сведет на нет всю цель функции Visual Studio User Secrets,
которую мы представили в главе 5, Модель данных с Entity Framework Core: держать
чтобы наши учетные данные не попадали в репозитории контроля исходных текстов.

Стоит отметить, что создание и настройка файла appsettings.Production.json не является специфической для Linux задачей; если бы мы опубликовали приложение WorldCitiesAPI на сервере Windows, нам пришлось бы
сделать то же самое.

Как только мы создали производственные пакеты для наших приложений WorldCities и WorldCitiesAPI, а также необходимые конфигурационные файлы, мы можем развернуть их на нашем сервере VM.

# Развертывание файлов на виртуальной машине Linux
Копирование производственных пакетов с нашей машины разработки на сервер Linux VM - это задача, которую
может быть выполнена многими способами, включая:
- использование существующего профиля публикации папок и последующее копирование файлов на веб-сервер с помощью
инструмент командной строки SCP
- Использование существующего профиля публикации папок и последующее копирование файлов на веб-сервер с помощью
Windows-клиента SFTP с графическим интерфейсом, например:
- Использование WinSCP: бесплатный SFTP, SCP, S3 и FTP-клиент для Windows: https://winscp.net/.
- Использование FTP-клиента FileZilla: Еще один бесплатный FTP-клиент с открытым исходным кодом, поддерживающий FTP через TLS
(FTPS) и SFTP: https://filezilla-project.org/.
- Установка FTP/FTPS-сервера на наш веб-сервер и последующая настройка профиля публикации FTP
- Использование профиля публикации виртуальной машины Azure в Visual Studio
В данном сценарии развертывания мы воспользуемся первым вариантом, который, вероятно, является самым простым;
Что касается других доступных альтернатив, то мы уже говорили о них в предыдущем разделе (Windows
Deployment), поэтому здесь мы не будем повторяться.

# Создание папки /var/www
Первое, что нам нужно сделать, это создать подходящую папку для хранения опубликованных файлов нашего приложения на
Linux VM. Для этого сценария развертывания мы будем использовать папку /var/www/<AppName>, тем самым
следуя типичному соглашению Linux; нет необходимости говорить, что, поскольку мы собираемся опубликовать два приложения, мы
создадим две папки.
Поскольку шаблон Azure на базе CentOS не поставляется с существующей папкой /var/www, нам нужно
создать и ее. Для этого выполните следующую команду в консоли Linux VM:
```
$ sudo mkdir /var/www
```
Эта папка /var/www/ будет нашим Linux-эквивалентом папки Windows C:\inetpub\, директории
которая будет содержать файлы наших веб-приложений.
Сразу после этого мы можем создать в ней две новые вложенные папки с помощью следующей команды:
```
$ sudo mkdir /var/www/WorldCities
$ sudo mkdir /var/www/WorldCitiesAPI
```
Эти две папки будут содержать опубликованные файлы нашего приложения.

# Установка разрешений
Теперь нам нужно настроить права доступа к папке /var/www/WorldCities для пользователя Nginx
пользователя по умолчанию.
В этом сценарии развертывания мы считаем само собой разумеющимся тот факт, что экземпляр Nginx запущен с
стандартным пользователем nginx и группой nginx. В других средах Linux имя пользователя и/или группа
могут отличаться - например, в некоторых дистрибутивах Linux группа Nginx называется www или www-data.
Чтобы определить, под каким пользователем запущен Nginx, выполните следующую команду:
$ ps -eo pid,comm,euser,supgrp | grep nginx
Чтобы получить список всех доступных пользователей и/или групп Linux, выполните следующие команды:
$ getent passwd
$ getent group
Получив пользователя и группу, мы можем использовать их для изменения разрешений папки /var/www.
Если принять значения по умолчанию (пользователь nginx и группа nginx), это можно сделать следующим образом:
$ sudo chown -R nginx:nginx /var/www
$ sudo chmod -R 550 /var/www
В результате пользователь nginx и соответствующая ему группа nginx смогут получить доступ к папке /var/www/
WorldCities в режиме чтения и выполнения, при этом заблокировав любой доступ для всех остальных пользователей/групп.
Прежде чем двигаться дальше, необходимо сделать еще одну вещь. Если мы хотим опубликовать наше приложение с помощью FTP, FTPS или SFTP,
вышеуказанных разрешений будет недостаточно; нам нужно обязательно установить их в соответствии с требованиями нашего FTP
требования к FTP-серверу и/или учетной записи, которую мы планируем использовать для выполнения задачи загрузки.

# Разрешения на публикацию
Наиболее распространенным способом установки прав на публикацию является использование команды Linux setfacl для
предоставить права на чтение и запись в папку /var/www для публикующей учетной записи.
Если мы планируем опубликовать наше приложение с помощью учетной записи пользователя, которую мы настроили в MS Azure, мы можем сделать это следующим образом
следующим образом:
$ sudo setfacl -R -m u:<USERNAME>:rwx /var/www
Обязательно замените предыдущее место <USERNAME> на имя пользователя, которое мы ранее установили
на ВМ Azure (то же самое, которое мы использовали для входа в терминал ВМ).

Для большинства сценариев достаточно установить разрешения, как описано выше;
Однако серверу может потребоваться дополнительная настройка в зависимости от дистрибутива и версии Linux
и версии, конфигурации системы и других параметров.

Теперь мы можем окончательно скопировать файлы.

# Копирование папки публикации WorldCities
После того как папки /var/www/WorldCities и /var/www/WorldCitiesAPI были правильно настроены на
Linux VM, мы можем открыть Command Prompt на нашей локальной машине разработки и начать копирование.
Начнем с Angular-приложения WorldCities. Используя Command Prompt, перейдите в корневую папку приложения
и выполните следующую SCP-команду, чтобы скопировать производственные пакеты, созданные с помощью команды ng build
на удаленную виртуальную машину:

```
> scp -r dist/WorldCities/* <USERNAME>@<VM.IP.ADDRESS>:/var/www/WorldCities
```
Не забудьте заменить местоимения <USERNAME> и <VM.IP.ADDRESS> на реальные значения.

Затем команда SCP спросит нас, хотим ли мы подключиться к удаленной папке, как показано на
следующий снимок экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/fc86fd94-6ec1-449a-97aa-aea4eb1d5c41)

Введите yes, чтобы разрешить соединение, а затем повторите команду, чтобы скопировать исходную папку в папку назначения
место назначения. Команда SCP начнет копировать все файлы с локальной машины разработки в
папку VM, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/ace001dd-b89a-48f8-89cb-78b0380d6a60)

Сразу после этого мы можем сделать то же самое для приложения WorldCItiesAPI - при условии, что мы уже опубликовали
его локально с помощью профиля публикации Folder.
Для этого перейдите в корневую папку проекта WorldCitiesAPI, а затем запустите следующую команду SCM
команду:
```
> scp -r bin/Release/net6.0/publish/* <USERNAME>@<VM.IP.ADDRESS>:/var/www/
WorldCitiesAPI
```

Если мы создали файл appsettings.Production.json внутри проекта (плохая практика), он будет
развернут внутри остальной части приложения, то есть нам придется вручную редактировать его на сервере VM;
если мы создали его отдельно (хорошая практика), то теперь мы можем воспользоваться возможностью либо создать его локально
и затем загрузить его с помощью инструмента SCP, либо создать его непосредственно на сервере VM с помощью текстового редактора, такого как
nano или vim. Обязательно сделайте это, прежде чем продолжить.
Теперь, когда файлы приложения WorldCities скопированы на виртуальную машину Linux, нам нужно настроить службу
службу Kestrel, а затем обратный прокси Nginx для ее обслуживания.


# Настройка Kestrel и Nginx
Прежде чем начать, мы быстро объясним, как служба Kestrel и HTTP-сервер Nginx будут взаимодействовать друг с другом.
Высокоуровневая архитектура очень похожа на модель внепроцессного хостинга Windows, которая
которая используется со времен ASP.NET Core 2.2:
- Служба Kestrel будет обслуживать наше веб-приложение на TCP-порту 5000 (или любом другом TCP-порту; 5000 - это
только по умолчанию)
- HTTP-сервер Nginx будет действовать как обратный прокси, перенаправляя все входящие запросы на
веб-серверу Kestrel.
Этот паттерн называется edge-origin proxy, и вкратце его можно представить в виде следующей диаграммы:

![image](https://github.com/artemovsergey/Angular/assets/26972859/66fa9694-ba03-45c6-b0be-6e6db5570882)

Теперь, когда мы поняли общую картину, давайте сделаем все возможное, чтобы реализовать ее.
Поскольку наше приложение будет работать по протоколу HTTPS, нам нужно либо приобрести и установить сертификат TLS/SSL
у стороннего реселлера, либо создать самоподписанный.
В данном конкретном сценарии мы будем считать, что у нас есть действующий сертификат, как и в случае с
Windows: однако, чтобы помочь тем, у кого его нет, мы вкратце объясним, как создать самоподписанный сертификат в Linux с помощью OpenSSL.
сертификат в Linux с помощью инструмента командной строки OpenSSL.

# Создание самоподписанного SSL-сертификата
Если у вас уже есть действующий сертификат TLS/SSL, вы можете пропустить следующее руководство и перейти к
Следующий раздел: нам просто нужно скопировать файлы сертификата в папку /var/www/ssl сервера VM
что можно сделать с помощью SCP так же, как мы делали это с производственными файлами приложения.
Если вам нужно создать самоподписанный сертификат, вот что вам нужно сделать:
1. Создайте папку /var/www/ssl с помощью команды sudo mkdir /var/www/ssl
2. Создайте самоподписанный SSL-сертификат (worldcities.crt) и файл закрытого ключа (worldcities.
key) с помощью следующей команды:
```
$ sudo openssl req -x509 -newkey rsa:4096 -sha256 -nodes -keyout /var/www/ssl/worldcities.key -out /var/www/ssl/worldcities.crt -subj "/
CN=worldcities.io" -days 3650
```
3. После этого объедините сертификат и закрытый ключ в один файл worldcities.pfx:
```
$ sudo openssl pkcs12 -export -out /var/www/ssl/worldcities.pfx -inkey /
var/www/ssl/worldcities.key -in /var/www/ssl/worldcities.crt
```
Когда вас попросят ввести пароль файла PFX, введите произвольный пароль и запомните его как "пароль сертификата
пароль" для последующего использования.

# Установка прав доступа к папке SSL
Независимо от того, как мы его получили, теперь у нас должен быть сертификат TLS/SSL в папке /var/www/ssl:
это означает, что теперь нам нужно установить правильные разрешения на эту папку, чтобы она была доступна как для Nginx, так и для приложения.
Nginx и приложения, точно так же, как мы делали это с папкой /var/www:
```
$ sudo chown -R nginx:nginx /var/www/ssl
$ sudo chmod -R 550 /var/www/ssl
```
В этом конкретном случае мы должны выполнить дополнительный шаг: точнее, нам нужно изменить контекст безопасности
контекст безопасности папки /var/www/ssl (и всех содержащихся в ней файлов), чтобы Nginx смог получить к ней доступ:
```
$ sudo chcon -R -v --type=httpd_sys_content_t /var/www/ssl
```
Если мы не выполним предыдущую команду, Security-Enhanced Linux (SELinux) запретит httpd
демоны не смогут получить доступ к папке /var/www/ssl, что вызовет нежелательные ошибки "разрешение отклонено" во время
на этапе запуска Nginx. Само собой разумеется, что если в нашей Linux-системе не работает SELinux или
мы навсегда отключили его, предыдущую команду можно пропустить. Однако, поскольку она активна
в шаблоне ВМ MS Azure на базе CentOS, нам может понадобиться ее выполнить.

SELinux - это механизм безопасности управления доступом (MAC), реализованный в ядре CentOS 4.
ядре. Он очень похож на механизм UAC в Windows и имеет сильные значения по умолчанию.
которые могут быть ослаблены в случае особых требований.
Чтобы временно отключить его, выполните команду терминала sudo setenforce 0. Это
может быть полезно при возникновении проблем с разрешениями, чтобы определить, связана ли проблема с
связана ли проблема с SELinux.
Дополнительную информацию о SELinux и его настройках безопасности по умолчанию можно найти на следующих сайтах
следующие URL-адреса:
https://wiki.centos.org/HowTos/SELinux
https://wiki.centos.org/TipsAndTricks/SelinuxBooleans
Дополнительные сведения об инструменте OpenSSL см. по следующему URL:
https://www.openssl.org/docs/manmaster/man1/openssl.html

Теперь у нас есть действительный самоподписанный сертификат TLS/SSL, который может использоваться Nginx.

# Настройка службы systemd
Теперь, когда у нас есть сертификат TLS/SSL и мы установили соответствующие права на его папку /var/www/ssl
мы можем создать запись systemd для регистрации WorldCitiesAPI в качестве службы. Сайт
Ангулярное приложение WorldCities не нуждается в Kestrel и поэтому потребует гораздо меньше работы, поскольку оно
все дело в обслуживании статических файлов.
Начнем с создания файла определения сервиса в папке /etc/systemd/system/.
Для этого мы воспользуемся nano, текстовым редактором с открытым исходным кодом для Linux, который можно использовать из командной строки
(похож на vim, но гораздо проще в использовании). Давайте выполним следующие шаги:

1. Выполните следующую команду, чтобы создать новый файл /etc/systemd/system/kestrelWorldCitiesAPI.service:
```
$ sudo nano /etc/systemd/system/kestrel-WorldCitiesAPI.service
```
После этого заполните только что созданный файл следующим содержимым:

```
[Unit]
Description=WorldCitiesAPI
[Service]
WorkingDirectory=/var/www/WorldCitiesAPI
ExecStart=/usr/local/bin/dotnet /var/www/WorldCitiesAPI/WorldCitiesAPI.
dll
Restart=always
# Restart service after 10 seconds if the dotnet service crashes:
RestartSec=10
KillSignal=SIGINT
SyslogIdentifier=WorldCitiesAPI
User=nginx
Environment=ASPNETCORE_ENVIRONMENT=Production
Environment=DOTNET_PRINT_TELEMETRY_MESSAGE=false
Environment=ASPNETCORE_URLS=http://localhost:5000
# How many seconds to wait for the app to shut down after it receives the
initial interrupt signal.
# If the app doesn't shut down in this period, SIGKILL is issued to
terminate the app.
# The default timeout for most distributions is 90 seconds.
TimeoutStopSec=90
[Install]
WantedBy=multi-user.target
```
3. После этого нажмите Ctrl + X, чтобы выйти, а затем Y, чтобы сохранить файл на диске.

Файл kestrel-WorldCitiesAPI.service доступен в папке /_LinuxVM_ConfigFiles/ этого
репозитория GitHub этой книги.
В зависимости от дистрибутива Linux, исполняемый файл dotnet может находиться в папках, отличных от
usr/bin, например, /usr/share/bin, /usr/local/bin или /usr/share/dotnet: обязательно проверьте это.
Как мы видим, содержимое этого файла будет использовано systemd для запуска проекта WorldCitiesAPI с нашими
производственными значениями нашего приложения, такими как переменная ASPNETCORE_ENVIRONMENT, о которой мы говорили ранее
и TCP-порт, который будет использоваться для внутреннего обслуживания приложения.

Приведенные выше параметры подходят для нашего текущего сценария развертывания, однако их следует
должны быть изменены, чтобы соответствовать различным именам пользователей, именам папок, используемым TCP-портам, имени основной DLL веб-приложения и т. д.
имя основной DLL приложения и так далее. При размещении другого веб-приложения не забудьте
обновить их соответствующим образом.

Теперь, когда мы настроили службу, нам нужно ее запустить, что можно сделать с помощью следующей команды:
```
$ sudo systemctl start kestrel-WorldCitiesAPI.service
```
Если вы также хотите, чтобы служба автоматически запускалась при каждой перезагрузке виртуальной машины, добавьте следующую команду:
```
$ sudo systemctl enable kestrel-WorldCitiesAPI.service
```

Сразу после этого стоит выполнить следующую команду, чтобы проверить, работает ли служба
работает без проблем:
```
$ sudo systemctl status kestrel-WorldCitiesAPI.service
```
Если мы увидим зеленую надпись active (running), как на следующем скриншоте, это, скорее всего, означает, что наш веб-сервис Kestrel
скорее всего, означает, что наша веб-служба Kestrel работает:

![image](https://github.com/artemovsergey/Angular/assets/26972859/20da587a-488e-4ea3-a567-5499bee3b40c)

Если команда status показывает, что что-то не так (красные линии или советы), мы можем устранить проблему
просмотрев подробный журнал ошибок приложения ASP.NET Core с помощью следующей команды:
```
$ sudo journalctl -u kestrel.worldcities
```
Параметр -u будет возвращать только сообщения, поступающие от службы kestrel-WorldCitiesAPI, отфильтровывая все остальное.
Поскольку журнал journalctl может легко стать очень длинным, даже при использовании предыдущего фильтра, также может быть
целесообразно ограничить его временные рамки с помощью параметра --since следующим образом:
```
$ sudo journalctl -u kestrel-worldcities --since "yyyy-MM-dd HH:mm:ss"
```
Обязательно замените местоимения yyyy-MM-dd HH:mm:ss на подходящее значение даты.
И последнее, но не менее важное: мы можем просто вывести последнюю занесенную в журнал ошибку с помощью ключа -xe:
```
$ sudo journalctl -xe
```
Эти команды должны быть очень полезны для эффективного устранения большинства ошибок в Linux.

Если служба kestrel-worldcities.service запущена, наша работа на этом закончена: мы успешно
настроили systemd на запуск проекта WorldCitiesAPI в качестве службы, которая размещается на ASP.NET Core
используя веб-сервер Kestrel. Теперь нам осталось настроить Nginx на обратный прокси Kestrel, и все готово.

Однако прежде чем это сделать, стоит потратить минуту на то, чтобы понять, зачем нам вообще нужно строить
такой шаблон edge-origin в первую очередь.
Почему мы не обслуживаем веб-приложение с помощью Kestrel напрямую?
У нас может возникнуть соблазн просто настроить веб-службу Kestrel на TCP-порт 443 (вместо TCP 5000)
и выполнить работу прямо сейчас, без необходимости работать с Nginx и пропустить всю часть обратного прокси.
Несмотря на то, что это возможно на 100%, мы настоятельно рекомендуем не делать этого по тем же причинам, которые указаны
Microsoft здесь:

Kestrel отлично подходит для обслуживания динамического контента из ASP.NET Core. Однако возможности
возможности обслуживания не так многофункциональны, как у таких серверов, как IIS, Apache или Nginx. A
обратный прокси-сервер может разгрузить работу, такую как обслуживание статического содержимого, кэширование запросов,
сжатие запросов и завершение SSL от HTTP-сервера. Обратный прокси-сервер
может располагаться на отдельной машине или быть развернутым рядом с HTTP-сервером.
[Источник: https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/
linux-nginx]

Короче говоря, Kestrel не предназначен для использования на передовой, по крайней мере, в настоящее время; поэтому правильнее всего
правильнее всего держать его подальше от передовой и оставить такую задачу Nginx.

# Настройка Nginx для WorldCitiesAPI
Последнее, что нам нужно сделать, - это настроить HTTP-сервер Nginx на работу в качестве обратного прокси для нашего
Kestrel. Выполните следующие шаги:
1. Введите следующую команду, чтобы создать специальный файл конфигурации Nginx для этой работы:
```
$ sudo nano /etc/nginx/nginx-WorldCitiesAPI.conf
```
2. Затем заполните содержимое нового файла следующими параметрами конфигурации:
```json
server {
 listen 80;
 listen [::]:80;
 server_name worldcities-api-2022.ryadel.com;
 return 301 https://worldcities-api-2022.ryadel.com$request_uri;
}
server {
 listen 443 ssl http2;
 listen [::]:443 ssl http2;
 ssl_certificate /var/www/ssl/star_ryadel_com.crt;
ssl_certificate_key /var/www/ssl/star_ryadel_com.key;
 server_name worldcities-api-2022.ryadel.com;
 root /var/www/WorldCitiesAPI/;
 index index.html;
 autoindex off;
 location / {
 proxy_pass http://localhost:5000;
 proxy_http_version 1.1;
 proxy_cache_bypass $http_upgrade;
 proxy_set_header Connection $http_connection;
 proxy_set_header Host $host;
 proxy_set_header Upgrade $http_upgrade;
 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
 proxy_set_header X-Forwarded-Host $host:$server_port;
 proxy_set_header X-Forwarded-Proto $scheme;
 proxy_set_header X-Forwarded-Server $host;
 }
}
```
3. После этого нажмите Ctrl + X, чтобы выйти, а затем Y, чтобы сохранить файл.
4. Сразу после этого выполните следующую команду, чтобы разрешить службе Nginx подключаться к
сети:
```
$ sudo setsebool -P httpd_can_network_connect 1
```
Выполнение предыдущей команды, вероятно, займет некоторое время, однако она необходима для изменения
настройки SELinux по умолчанию, которые не позволяют всем демонам httpd (таким как Nginx) получить доступ к
локальной сети и, следовательно, к службе Kestrel. Если в нашей Linux-системе не работает SELinux или мы
мы его отключили, нам не нужно выполнять предыдущую команду.
Пока мы здесь, мы можем воспользоваться возможностью настроить Nginx для обслуживания Angular-приложения WorldCities
также.

# Настройка Nginx для WorldCities
Приложение Angular не обслуживается Kestrel локально, поэтому нет необходимости проксировать его: Nginx просто нужно
обслуживать его статические файлы, действуя, таким образом, как обычный веб-сервер.

Чтобы настроить его на такое поведение, создайте новый файл конфигурации Nginx следующим образом:
```
$ sudo nano /etc/nginx/nginx-WorldCitiesAPI.conf
```
И заполните его следующим содержимым:

```json
server {
 listen 80;
 listen [::]:80;
 server_name worldcities-2022.ryadel.com;
 return 301 https://worldcities-2022.ryadel.com$request_uri;
}
server {
 listen 443 ssl http2;
 listen [::]:443 ssl http2;
 ssl_certificate /var/www/ssl/star_ryadel_com.crt;
 ssl_certificate_key /var/www/ssl/star_ryadel_com.key;
 server_name worldcities-2022.ryadel.com;
 root /var/www/WorldCities/;
 index index.html;
 autoindex off;
}
```
Как мы видим, на этот раз мы имеем дело с гораздо более простым конфигурационным файлом, поскольку нам не нужно
ничего проксировать.

Теперь давайте посмотрим, как мы можем указать Nginx читать эти новые конфигурационные файлы при запуске.

# Обновление файла nginx.conf
Два конфигурационных файла, которые мы только что добавили, должны быть указаны в основном конфигурационном файле Nginx
иначе они не будут прочитаны и применены.
Для этого отредактируйте файл /etc/nginx/nginx.conf с помощью следующей команды:
```
$ sudo nano /etc/nginx/nginx.conf
```
Затем добавьте следующие выделенные строки в конец файла, непосредственно перед последней закрывающей квадратной
скобка:

```json
location / {
 }
 error_page 404 /404.html;
 location = /40x.html {
 }
 error_page 500 502 503 504 /50x.html;
 location = /50x.html {
 }
 }
 server_names_hash_bucket_size 128;
 include nginx-WorldCities.conf;
 include nginx-WorldCitiesAPI.conf;
 # ...existing code...
}
```
Эти включаемые строки позволят Nginx читать эти конфигурационные файлы и действовать соответствующим образом: обратное проксирование приложения WorldCitiesAPI ASP.NET Core и прямое обслуживание приложения WorldCities Angular. Новые
будут применены, как только Nginx будет перезапущен, что мы и сделаем в ближайшее время.

Как видно из приведенного выше кода, мы также воспользовались возможностью увеличить значение
server_names_hash_bucket_size по умолчанию (64) до 128, что позволяет обрабатывать
более длинные имена хостов, такие как те, что используются в нашем сценарии.

Все необходимые задачи по развертыванию на Linux выполнены. Осталось только правильно протестировать
веб-приложения WorldCities и WorldCitiesAPI, чтобы убедиться, что они работают.

# Тестирование WorldCities и WorldCitiesAPI
Этап тестирования будет очень похож на тот, что мы делали в конце раздела по развертыванию Windows.
Выполните следующие шаги:
1. Прежде чем покинуть терминал Linux VM, следует перезапустить службы Kestrel и
Nginx следующим образом:
```
$ sudo systemctl restart kestrel-WorldCitiesAPI
$ sudo systemctl restart nginx
```
2. Сразу после этого проверьте их состояние с помощью следующих команд, чтобы убедиться, что
что они работают:
```
$ sudo systemctl status kestrel-WorldCitiesAPI
$ sudo systemctl status nginx
```
В производственных средах рекомендуется протестировать обновленную конфигурацию Nginx перед перезапуском
Nginx с помощью следующей команды:
```
sudo nginx -t
```
Таким образом, производственный сайт не упадет, если Nginx не сможет загрузиться из-за какой-либо ошибки в конфигурации.
Теперь мы готовы переключиться на нашу локальную машину разработки и начать тест.

# Тестирование приложения
И снова мы будем выполнять эти тесты с помощью браузера на базе Chromium (Google Chrome или Microsoft Edge), поскольку их встроенные средства разработки позволяют удобно проверять наличие Web
App Manifest и наличие рабочих служб.
Запустите Google Chrome и напишите публичный URL-адрес приложения Angular в адресной строке браузера:
https://worldcities-2022.ryadel.com

Если мы все сделали правильно, мы должны увидеть домашнюю страницу приложения WorldCities Angular
вид:

![image](https://github.com/artemovsergey/Angular/assets/26972859/bf381e8b-28d0-4acb-bfb5-59e56e22ea6a)

Оттуда мы должны проверить наличие/недостаточность следующих вещей:
- Файл манифеста приложения (со всеми иконками HC) в панели Application | Manifest консоли разработки браузера
- Правильно зарегистрированный рабочий сервис в панели Application | Service Workers консоли разработки браузера
консоли разработки браузера
- Значки "Отправить эту страницу" и "Установить" в правой части адресной строки браузера
- Поведение работника службы при установке и снятии флажка оффлайн-статуса для проверки
поведение работника службы
- Доступ к базе данных SQL
- Реактивные формы редактирования города и редактирования страны
- Рабочие процессы входа и регистрации
Если все работает так, как ожидалось, мы можем сказать, что наш путь развертывания Linux также закончен. В
В следующем разделе мы рассмотрим, как справиться с некоторыми типичными сообщениями об ошибках ASP.NET Core, чтобы понять
потенциальные проблемы, которые могут возникнуть на этапе развертывания или после него, и правильно их решить.

# Устранение неполадок
Если веб-приложение столкнулось с ошибкой во время выполнения, в производственной среде не будет показана подробная
подробной информации об исключении конечному пользователю. По этой причине мы не сможем узнать ничего
если мы не переключимся в режим разработки (см. следующий снимок экрана):

![image](https://github.com/artemovsergey/Angular/assets/26972859/057b6cc2-2e2d-48f4-8f68-9a25891f7973)

Это можно сделать следующим образом:
1. Измените значение переменной ASPNETCORE_ENVIRONMENT на Development в файле настроек службы WorldCitiesAPI
в файле настроек службы влияющего приложения.
2. Перезапустите службу (и перегенерируйте дерево зависимостей после этого) с помощью следующих команд:
```
$ sudo systemctl restart kestrel-WorldCitiesAPI
$ sudo systemctl daemon-reload
```
Однако настоятельно рекомендуется никогда не делать этого в реальных производственных средах и проверять
журналы службы WorldCitiesAPI с помощью следующих команд journalctl, как мы и предлагали ранее:
```
$ sudo journalctl -u kestrel-WorldCitiesAPI --since "yyyy-MM-dd HH:mm:ss"
$ sudo journalctl -xe
```
Такой подход даст нам тот же уровень информации, не выставляя наши ошибки на всеобщее обозрение.
Теперь, когда мы закончили с Linux, мы готовы изучить нашу последнюю - но не последнюю - альтернативу развертывания: Azure App Service.

# Развертывание службы приложений Azure App Service
В этом разделе мы узнаем, как развернуть наши веб-приложения HealthCheck и HealthCheckAPI на MS Azure App Service, полностью управляемой платформе для создания, развертывания и масштабирования веб-приложений.
Как мы сможем убедиться, это развертывание значительно проще и быстрее, чем предыдущие,
потому что нам не нужно будет разворачивать виртуальную машину; полностью управляемый подход App Service обеспечивает
подход App Service обеспечивает опыт развертывания, подобный тому, который мы испытали в главе 5, Модель данных с Entity
Framework Core, когда мы создавали базу данных MS Azure: мы просто получим то, что нам нужно для публикации нашего
приложение, без необходимости выполнять какую-либо настройку оборудования и/или программного обеспечения.

Такой подход может стать огромным преимуществом для большинства проектов, если нам не нужно выполнять
сложных низкоуровневых задач по настройке инфраструктуры.
Вот что мы сделаем в деталях:
- Создадим два экземпляра Web App в MS Azure для наших приложений HealthCheck и HealthCheckAPI,
используя тарифный план free-tier (F1).
- Адаптируем наши приложения, чтобы они оба работали с общедоступными URL-адресами службы App Service
- Опубликуйте наши приложения в Azure App Service с помощью FTPS (для приложения Angular) и Visual Studio
(для приложения ASP.NET Core)
- Протестируйте наши новые экземпляры службы App Service, чтобы убедиться, что они работают так, как ожидалось.
Это будет наш последний набор задач: давайте их выполним!

# Создание экземпляров службы App Service
Перейдите на сайт https://portal.azure.com/ и войдите в систему под своей учетной записью. После этого введите app service в
в строке поиска и выберите функцию App Service. Далее нам нужно создать два новых экземпляра: давайте
начнем с приложения HealthCheck Angular.

# Добавление службы приложений HealthCheck
После этого нажмите на кнопку Add в самом верхнем меню, чтобы открыть форму Create Web App, показанную
на следующем скриншоте:

![image](https://github.com/artemovsergey/Angular/assets/26972859/0118e834-db1d-4fb8-bbae-5b286fd464e8)

Заполните необходимые поля следующим образом:
- Имя: Это будет уникальное имя экземпляра нашего веб-приложения, которое также будет использоваться в качестве поддомена публичного
поддомена URL. На предыдущем снимке экрана мы использовали HealthCheck-2022, но подойдет любое
имя подойдет.
- Опубликовать: Выберите Code, если вы не хотите размещать приложение в управляемом контейнере Docker.
- Стек времени выполнения: Выберите .NET 6. По правде говоря, подойдет любой стек, поскольку мы собираемся использовать эту запись
запись App Service для публикации пакета нашего приложения Angular, состоящего только из статических HTML, JS,
и CSS-файлов.
- Операционная система: Выберите Windows, поскольку в начале этой главы мы оптимизировали наше приложение HealthCheck для развертывания на Windows OS.
- Регион: Выберите регион, наиболее близкий к нашему географическому положению.
- План обслуживания приложения: Выберите подходящий план или просто выберите бесплатный план (F1), если вы хотите только протестировать
службу - как мы сделали на предыдущем снимке экрана.
- Подписка: Выберите подписку на MS Azure.
- Группа ресурсов: Используйте ту же группу ресурсов, которая используется для базы данных SQL и/или виртуальных машин (или
создайте новую).
После этого нажмите кнопку Review + Create в левой нижней части страницы, чтобы перейти на страницу обзора.
Затем нажмите кнопку Создать, чтобы начать процесс развертывания. Вся операция займет
несколько секунд, после чего мы сможем перейти к нашему только что созданному ресурсу:

![image](https://github.com/artemovsergey/Angular/assets/26972859/a12c59db-a38a-4150-9fba-778a810e8089)

Если мы нажмем на кнопку Перейти к ресурсу, то попадем на панель конфигурации экземпляра Web App,
где есть множество доступных опций:

![image](https://github.com/artemovsergey/Angular/assets/26972859/46a5db6d-f2f3-4f09-bfe7-869ea43a9b2b)

Однако сейчас нам не нужны никакие из этих настроек; нам просто нужно получить публичный URL нашего
приложения, который будет иметь формат https://<appname>.azurewebsites.net/.
Как видно на предыдущем снимке экрана, публичный URL-адрес нашего экземпляра веб-приложения https://.
healthcheck-2022.azurewebsites.net/.
Запомните этот URL, поскольку он нам скоро понадобится. Если мы перейдем по нему, то увидим
приветственное окно, информирующее нас о том, что управляемый экземпляр готов к размещению нашего веб-приложения, и предлагающее нам
развернуть наш код, что мы и собираемся сделать через некоторое время - после создания другого экземпляра
App Service для нашего приложения HealthCheckAPI ASP.NET Core.

# Добавление службы приложений HealthCheckAPI
Чтобы добавить еще один экземпляр службы App Service для нашего приложения HealthCheckAPI ASP.NET Core, нам нужно повторить
те же шаги, которые мы только что проделали для создания предыдущего. Единственный параметр, который нам нужно изменить, это
Имя экземпляра, которое мы можем установить на HealthCheck-API-2022.
После создания экземпляра HealthCheck-API-2022 мы можем воспользоваться возможностью настроить
параметры CORS для этого экземпляра App Service, поскольку эти параметры будут переопределять любые политики CORS
применяемые на уровне ASP.NET Core.
Перейдите на страницу CORS с помощью древовидного представления левого меню и добавьте публичный URL-адрес экземпляра службы приложений HealthCheck-2022
экземпляра службы приложений, который мы создали в самом начале, в список разрешенных источников, как показано на следующем снимке экрана
снимок экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/0b012464-d309-407e-81ab-d170be82767e)

После этого вернитесь на страницу обзора экземпляра и обратите внимание на публичный URL, который должен быть
что-то вроде следующего: https://healthcheck-api-2022.azurewebsites.net/.
Теперь, когда мы знаем общедоступные URL-адреса наших экземпляров App Service, мы можем адаптировать наши приложения HealthCheck и
HealthCheckAPI для работы с ними.

# Адаптация наших приложений для работы с App Service
Если мы хотим, чтобы наше приложение HealthCheck Angular корректно работало с веб-интерфейсом HealthCheckAPI, нам необходимо
необходимо изменить значение baseUrl в файле /environments/environment.prod.ts, заменив существующее значение
существующее значение.
Вот как мы можем это сделать (обновленное значение выделено):

```ts
export const environment = {
 production: true,
 baseUrl: "https://healthcheck-api-2022.azurewebsites.net/"
};
```
В репозитории GitHub для этой главы вместо замены предыдущего значения мы добавили новый ключ
baseUrl_AppSettings и поместили туда новое значение, чтобы читателю были доступны оба URL для просмотра: нет необходимости говорить, что ключ baseUrl_AppSettings не будет иметь никакого эффекта - он предназначен только для справочных целей.
только в справочных целях.

Что касается приложения HealthCheckAPI, то нам ничего не нужно делать: мы даже не должны изменять значение
AllowedCORS в файле appsettings.Production.json, поскольку CORS-заголовки управляются
службой Azure App Service.
Тем не менее, если мы все равно хотим изменить их, чтобы отразить местоположение приложения Angular, вот как мы можем это сделать
сделать это (обновленное значение выделено):
```json
{
 "AllowedCORS": "https://healthcheck-2022.azurewebsites.net/"
}
```
Опять же, в репозитории GitHub для этой главы мы добавили новый ключ AllowedCORS_AppSettings
вместо замены предыдущего значения, чтобы сохранить оба URL для справочных целей.
Теперь мы можем перейти к задачам публикации.

# Публикация наших приложений в App Service
В этом разделе мы рассмотрим, как опубликовать наши приложения HealthCheck и HealthCheckAPI в экземпляре App
Service, который мы создали некоторое время назад.

# Публикация приложения Angular
Начнем с нашего Angular-приложения HealthCheck.
Первое, что нужно сделать, это пересобрать его с помощью команды ng build, чтобы пакет Angular был
обновлен с учетом последних изменений, которые мы внесли.
Сразу после этого вернитесь к нашему новому экземпляру службы приложений HealthCheck-2022 на портале управления MS Azure. Там перейдите к пункту меню Развертывание > Центр развертывания, используя
главного древовидного представления слева, затем выберите вкладку Учетные данные FTPS, как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/0b8f3b01-1fa8-4e8f-97e1-adb81e24b8d2)

Обратите внимание на URL конечной точки FTPS, а также на имя пользователя и пароль Application Scope.
Эти настройки нужны нам для загрузки пакета Angular с локальной машины разработки на экземпляр службы приложений HealthCheck-2022 по протоколу FTP/FTPS.
машины в экземпляр службы приложений HealthCheck-2022 по протоколу FTP/FTPS.

Для экономии места мы не будем объяснять, как установить FTPS-соединение, используя приведенную выше информацию.
Мы не будем объяснять, как установить FTPS-соединение с помощью приведенной выше информации, поскольку это довольно тривиальная задача, с которой можно легко справиться с помощью бесплатного
FileZilla, FTP Voyager или WinSCP: вместо этого мы доверимся читателю.
сможет сделать это самостоятельно.

Во время публикации нашего приложения Angular на экземпляре App Service мы можем воспользоваться возможностью удалить файл
файл hostingstart.html, содержащий HTML-код для экрана приветствия App Service, который мы видели в самом начале
в самом начале, поскольку он нам больше не нужен.
Когда процесс FTPS-загрузки завершен, нам осталось сделать еще одну вещь перед публикацией: добавить
расширение файла .webmanifest в список типов MIME, поддерживаемых экземпляром App Service,
иначе он не будет обслуживаться клиентами и сервисный работник не будет работать.

# Настройка MIME-типа webmanifest
К сожалению, на момент написания статьи в App Service не было раздела GUI для настройки MIME
типов. Единственный способ сделать это - минимальный файл web.config со следующим содержимым:

```xml
<?xml version="1.0" encoding="utf-8"?>
<configuration>
 <system.webServer>
 <staticContent>
 <remove fileExtension=".webmanifest" />
 <mimeMap fileExtension=".webmanifest" mimeType="application/
manifest+json" />
 </staticContent>
 </system.webServer>
</configuration>
```
Чтобы быстро выполнить эту задачу, мы можем создать этот файл web.config на нашей машине разработки, а затем
опубликовать его на рабочем сервере с помощью FTPS.
В качестве альтернативы мы можем создать этот файл с помощью графического интерфейса сайта портала MS Azure благодаря функции App Service
Editor, которая в настоящее время находится в стадии предварительного просмотра, но полностью готова для этой конкретной цели. Для этого
выполните следующие задачи:
1. Перейдите на портал MS Azure
2. Перейдите на страницу управления HealthCheck-2022
3. Перейдите на вкладку App Service Editor (предварительный просмотр).

После этого, пропустив пару экранов помощи/инструкций, мы получим доступ к аккуратному веб-менеджеру File
Manager, который позволяет нам просматривать и редактировать все файлы экземпляра App Service, которые мы загрузили в самом начале.
Мы можем использовать этот инструмент для создания нового файла web.config и заполнения его вышеуказанным содержимым прямо из
как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/0fb63dd9-9247-4795-b851-2aef737f2a11)

Сразу после этого мы можем перейти к проекту HealthCheckAPI ASP.NET Core.

# Публикация проекта ASP.NET Core
Чтобы опубликовать наш проект HealthCheckAPI ASP.NET Core, у нас есть два варианта:
- Создать профиль публикации Visual Studio FTP (или использовать существующий), а затем применить тот же
метод загрузки на основе FTPS, который мы только что использовали в нашем проекте Angular.
- Создать профиль публикации Visual Studio Azure App Service и использовать его
Как всегда, выбор за нами: поскольку мы уже видели, как справиться с этой задачей с помощью FTPS, давайте вкратце
рассмотрим альтернативный путь.

Переключитесь обратно в Visual Studio. В Проводнике решений щелкните правой кнопкой мыши корневой узел проекта HealthCheckAPI
и выберите "Опубликовать", чтобы получить доступ к настройкам публикации.
Там выберите Azure, а затем Azure App Service (Windows), как показано на следующем снимке экрана:

![image](https://github.com/artemovsergey/Angular/assets/26972859/b5a1d16f-5971-4fb7-924a-505c0e466290)

В следующем разделе нам будет предложено войти в учетную запись MS Azure (если мы еще не связали ее
к Visual Studio); после этого нам будет предложено выбрать группу ресурсов и экземпляр службы App Service
внутри нее:

![image](https://github.com/artemovsergey/Angular/assets/26972859/6e020856-cee0-410d-a4ef-0ba964b54fe7)

Здесь мы можем выбрать экземпляр Web App, который мы создали некоторое время назад: после этого пропустите панель API
и нажмите Finish, чтобы сохранить профиль публикации.

Профиль публикации службы App Service HealthCheckAPI не будет доступен в проекте GitHub для
этой главы, поскольку он содержит личную информацию о подписке Azure: однако
для читателя не должно быть проблемой создать свой собственный профиль, это очень простой
и понятный процесс.

Сразу после этого мы можем нажать кнопку Publish и позволить Visual Studio творить свою магию в MS Azure: как только
как только процесс публикации завершится, мы, наконец, будем готовы выполнить наше финальное тестирование.

# Тестирование HealthCheck и HealthCheckAPI
Чтобы протестировать наши новые экземпляры App Service, нам нужно подключиться к публичному URL HealthCheck-2022:
https://healthcheck-2022.azurewebsites.net/.

Если мы все сделали правильно, мы должны увидеть наше приложение HealthCheck Angular в открытом доступе
в Интернете и полностью способное подключаться к приложению HealthCheckAPI ASP.NET Core:

![image](https://github.com/artemovsergey/Angular/assets/26972859/7a89a4de-3bce-4828-9ffa-b8b7b388ba3d)

Как видно на предыдущем снимке экрана, приложение обслуживается по протоколу HTTPS благодаря встроенному сертификату с подстановочным знаком
сертификату, предоставляемому MS Azure, что означает, что мы также сможем протестировать наш рабочий сервис без
приобретения SSL-сертификата.
Вот и все. Наши задачи по развертыванию ASP.NET Core и Angular подошли к концу. Мы искренне надеемся, что
что вы получили такое же удовольствие от чтения книги, как и мы от ее написания.

# Резюме
Наконец-то наше путешествие по ASP.NET Core и Angular подошло к концу. Наша последняя задача заключалась в том, чтобы
получить наши SPA - теперь уже с самыми необходимыми функциями PWA - готовыми к публикации
в подходящей производственной среде.
Первым делом мы изучили некоторые важные советы по развертыванию для наших внутренних и внешних фреймворков. Поскольку в шаблоне Visual Studio уже реализованы самые важные оптимизационные твики,
мы потратили немного драгоценного времени, чтобы как следует изучить и понять различные техники, которые можно использовать
для повышения производительности и безопасности нашего веб-приложения, когда нам нужно будет опубликовать его в Интернете.
Сразу после этого мы приступили к установке Windows, используя пошаговый подход. Мы создали
виртуальную машину Windows Server на портале MS Azure, а затем установили службу IIS и правильно
сконфигурировали ее для публикации существующих приложений HealthCheck и HealthCheckAPI в Интернете.
Затем мы перешли на Linux, где узнали, как развернуть наши приложения WorldCities и WorldCitiesAPI
на виртуальной машине на базе CentOS. Настроив ее должным образом, мы воспользовались возможностью реализовать
модель внепроцессного хостинга с помощью Kestrel и Nginx, которая является стандартным подходом для обслуживания
ASP.NET Core веб-приложений на Linux-платформах. Чтобы добиться этого, нам пришлось изменить некоторые
настройки внутреннего интерфейса нашего приложения WorldCitiesAPI, чтобы обеспечить его корректную работу за
обратным прокси.
В обоих вышеописанных сценариях мы использовали реальные доменные имена и SSL-сертификаты, что позволило нам
правильно протестировать рабочие службы: однако мы также узнали, как создавать самоподписанные сертификаты и
техники сопоставления хостов, которые могут быть полезны для тестирования или непроизводственного развертывания
с минимальными затратами.
Мы также тщательно проверили результат наших усилий по развертыванию с помощью веб-браузера с нашей машины разработки.
Последнее, что мы сделали, - развернули наше приложение HealthCheck на MS Azure App Service, полностью управляемую
платформу, которая отлично подходит для большинства проектов, не требующих сложных низкоуровневых настроек.
настройки.
Наше приключение с ASP.NET Core и Angular наконец-то закончилось. Это настолько богатая тема, что мы
мы могли бы провести еще больше времени, обсуждая фреймворки и совершенствуя наши проекты еще больше
Но, несмотря на это, вы должны быть довольны полученными результатами и усвоенными уроками.
Мы надеемся, что вам понравилась эта книга. Большое спасибо за прочтение

# Предлагаемые темы
Для получения дополнительной информации мы рекомендуем следующие темы: HTTPS, Secure Socket Layer (SSL), ASP.
NET Core, развертывание, HTTP Strict Transport Security (HSTS), General Data Protection Regulation (GDPR),
Сеть доставки контента (CDN) MS Azure, Open Web Application Security Project (OWASP), SQL Server, SQL Server Management Studio (SS).
Server, SQL Server Management Studio (SSMS), Windows Server, IIS, FTP-сервер, профили публикации, ASP.
NET Core In-process Hosting Model, ASP.NET Core Out-of-process Hosting Model, CentOS, Kestrel,
Nginx, обратный прокси, Forwarded Headers Middleware, SCP, FileZilla FTP Client, WinSCP, journalctl,
nano, HOST mapping, самоподписанный SSL сертификат, openssl, Security-Enhanced Linux (SELinux).





























